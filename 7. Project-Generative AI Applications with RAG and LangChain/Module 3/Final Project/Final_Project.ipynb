{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe663624-5be9-413e-8f51-616dfe347ac1",
   "metadata": {},
   "source": [
    "<center> <h1>Final Assignment </h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd21d767-4aed-4ae5-b9d7-c7b506d596db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install \"ibm-watsonx-ai==1.0.4\"\n",
    "!pip install \"langchain==0.2.1\" \n",
    "!pip install \"langchain-ibm==0.1.7\"\n",
    "!pip install \"langchain-community==0.2.1\"\n",
    "!pip install \"chromadb==0.4.24\"\n",
    "!pip install \"faiss-cpu==1.8.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8270ee-9e86-4457-8d29-9e8870cfb517",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install \"langchain-community==0.2.1\"\n",
    "!pip install \"pypdf==4.2.0\"\n",
    "!pip install \"PyMuPDF==1.24.5\"\n",
    "!pip install \"unstructured==0.14.8\"\n",
    "!pip install \"markdown==3.6\"\n",
    "!pip install \"jq==1.7.0\"\n",
    "!pip install \"pandas==2.2.2\"\n",
    "!pip install \"docx2txt==0.8\"\n",
    "!pip install \"requests==2.32.3\"\n",
    "!pip install \"beautifulsoup4==4.12.3\"\n",
    "!pip install \"nltk==3.8.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7fa748f-bc0c-4c52-b17d-482bc981d071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders.csv_loader import UnstructuredCSVLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29195726-3550-4d9c-a1d1-eb791bd7ed71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Comprehensive Review of Low-Rank\n",
      "Adaptation in Large Language Models for\n",
      "Efficient Parameter Tuning\n",
      "September 10, 2024\n",
      "Abstract\n",
      "Natural Language Processing (NLP) often involves pre-training large\n",
      "models on extensive datasets and then adapting them for specific tasks\n",
      "through fine-tuning. However, as these models grow larger, like GPT-3\n",
      "with 175 billion parameters, fully fine-tuning them becomes computa-\n",
      "tionally expensive. We propose a novel method called LoRA (Low-Rank\n",
      "Adaptation) that significantly reduces the overhead by freezing the orig-\n",
      "inal model weights and only training small rank decomposition matrices.\n",
      "This leads to up to 10,000 times fewer trainable parameters and reduces\n",
      "GPU memory usage by three times. LoRA not only maintains but some-\n",
      "times surpasses fine-tuning performance on models like RoBERTa, De-\n",
      "BERTa, GPT-2, and GPT-3. Unlike other methods, LoRA introduces\n",
      "no extra latency during inference, making it more efficient for practical\n",
      "applications. All relevant code an\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"paper.pdf\")\n",
    "\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "print(pages[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "017d2e18-df5b-47c2-b151-b4dd38527cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_text = \"\"\"\n",
    "\n",
    "\\documentclass{article}\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "\\maketitle\n",
    "\n",
    "\\section{Introduction}\n",
    "\n",
    "Large language models (LLMs) are a type of machine learning model that can be trained on vast amounts of text data to generate human-like language. In recent years, LLMs have made significant advances in various natural language processing tasks, including language translation, text generation, and sentiment analysis.\n",
    "\n",
    "\\subsection{History of LLMs}\n",
    "\n",
    "The earliest LLMs were developed in the 1980s and 1990s, but they were limited by the amount of data that could be processed and the computational power available at the time. In the past decade, however, advances in hardware and software have made it possible to train LLMs on massive datasets, leading to significant improvements in performance.\n",
    "\n",
    "\\subsection{Applications of LLMs}\n",
    "\n",
    "LLMs have many applications in the industry, including chatbots, content creation, and virtual assistants. They can also be used in academia for research in linguistics, psychology, and computational linguistics.\n",
    "\n",
    "\\end{document}\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5cfa96f-bf77-4a8b-b0fb-eb909dfac66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\\\documentclass{article}\\n\\n\\x08egin{document}\\n\\n\\\\maketitle\\n\\n\\\\section{Introduction}\\n\\nLarge language models (LLMs) are a type of machine learning model that can be trained on vast amounts of text data to generate human-like language. In recent years, LLMs have made significant advances in various natural language processing tasks, including language translation, text generation, and sentiment'),\n",
       " Document(page_content='analysis.\\n\\n\\\\subsection{History of LLMs}\\n\\nThe earliest LLMs were developed in the 1980s and 1990s, but they were limited by the amount of data that could be processed and the computational power available at the time. In the past decade, however, advances in hardware and software have made it possible to train LLMs on massive datasets, leading to significant improvements in'),\n",
       " Document(page_content='performance.\\n\\n\\\\subsection{Applications of LLMs}\\n\\nLLMs have many applications in the industry, including chatbots, content creation, and virtual assistants. They can also be used in academia for research in linguistics, psychology, and computational linguistics.\\n\\n\\\\end{document}')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import LatexTextSplitter\n",
    "latex_splitter = LatexTextSplitter(chunk_size=400, chunk_overlap=0)\n",
    "docs = latex_splitter.create_documents([latex_text])\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4dfd10a-663e-4af0-b62b-6b3e1dbd3c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.06722455, -0.023730014, 0.017487874, -0.013195301, -0.03958462]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embed_params = {\n",
    "    EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,\n",
    "    EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
    "}\n",
    "\n",
    "watsonx_embedding = WatsonxEmbeddings(\n",
    "    model_id=\"ibm/slate-125m-english-rtrvr\",\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    project_id=\"skills-network\",\n",
    "    params=embed_params,\n",
    ")\n",
    "\n",
    "query = \"How are you?\"\n",
    "\n",
    "query_result = watsonx_embedding.embed_query(query)\n",
    "\n",
    "print(len(query_result))\n",
    "query_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03a19392-6ca5-43d3-bc98-c6a5e7e7d591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-10 11:30:41--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Ec5f3KYU1CpbKRp1whFLZw/new-Policies.txt\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6363 (6.2K) [text/plain]\n",
      "Saving to: ‘new-Policies.txt’\n",
      "\n",
      "new-Policies.txt    100%[===================>]   6.21K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-10-10 11:30:41 (1.60 GB/s) - ‘new-Policies.txt’ saved [6363/6363]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Ec5f3KYU1CpbKRp1whFLZw/new-Policies.txt\"\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28a02f4d-a414-44d1-8d29-f1a16cb2f054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt.1'}, page_content='Smoking Restrictions: Smoking inside company buildings, offices, meeting rooms, and other enclosed')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "loader = TextLoader(\"new-Policies.txt\")\n",
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "embed_params = {\n",
    "    EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,\n",
    "    EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
    "}\n",
    "\n",
    "watsonx_embedding = WatsonxEmbeddings(\n",
    "    model_id=\"ibm/slate-125m-english-rtrvr\",\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    project_id=\"skills-network\",\n",
    "    params=embed_params,\n",
    ")\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "ids = [str(i) for i in range(0, len(chunks))]\n",
    "vectordb = Chroma.from_documents(chunks, watsonx_embedding, ids=ids)\n",
    "vectordb._collection.count()\n",
    "\n",
    "query = \"Smoking policy\"\n",
    "docs = vectordb.similarity_search(query, k = 1)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6062e47c-7f2e-42e7-94fe-558485b90279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models.extensions.langchain import WatsonxLLM\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e73c791-f3b3-490b-a2d9-5d556b25bb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-10 11:37:15--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Ec5f3KYU1CpbKRp1whFLZw/new-Policies.txt\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6363 (6.2K) [text/plain]\n",
      "Saving to: ‘new-Policies.txt’\n",
      "\n",
      "new-Policies.txt    100%[===================>]   6.21K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-10-10 11:37:15 (1.32 GB/s) - ‘new-Policies.txt’ saved [6363/6363]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Ec5f3KYU1CpbKRp1whFLZw/new-Policies.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b56d3fff-d87c-4a2c-8244-c236ab4583f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt.1'}, page_content='to this policy. Non-compliance may lead to appropriate disciplinary action, which could include')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def llm():\n",
    "    model_id = 'mistralai/mixtral-8x7b-instruct-v01'\n",
    "    \n",
    "    parameters = {\n",
    "        GenParams.MAX_NEW_TOKENS: 256,  # this controls the maximum number of tokens in the generated output\n",
    "        GenParams.TEMPERATURE: 0.5, # this randomness or creativity of the model's responses\n",
    "    }\n",
    "    \n",
    "    credentials = {\n",
    "        \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "    project_id = \"skills-network\"\n",
    "    \n",
    "    model = ModelInference(\n",
    "        model_id=model_id,\n",
    "        params=parameters,\n",
    "        credentials=credentials,\n",
    "        project_id=project_id\n",
    "    )\n",
    "    \n",
    "    mixtral_llm = WatsonxLLM(model = model)\n",
    "    return mixtral_llm\n",
    "\n",
    "def text_splitter(data, chunk_size, chunk_overlap):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks\n",
    "def watsonx_embedding():\n",
    "    embed_params = {\n",
    "        EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,\n",
    "        EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
    "    }\n",
    "    \n",
    "    watsonx_embedding = WatsonxEmbeddings(\n",
    "        model_id=\"ibm/slate-125m-english-rtrvr\",\n",
    "        url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "        project_id=\"skills-network\",\n",
    "        params=embed_params,\n",
    "    )\n",
    "    return watsonx_embedding\n",
    "\n",
    "loader = TextLoader(\"new-Policies.txt\")\n",
    "txt_data = loader.load()\n",
    "chunks_txt = text_splitter(txt_data, 200, 20)\n",
    "vectordb = Chroma.from_documents(chunks_txt, watsonx_embedding())\n",
    "\n",
    "query = \"Email policy\"\n",
    "retriever = vectordb.as_retriever()\n",
    "docs = retriever.invoke(query)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 1})\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87dc934-b684-49b8-aa0a-d85a2593d6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Instruction-Tuning with LLMs\n",
    "\n",
    "\n",
    "Instruction-based fine-tuning, referred to as instruction GPT. It trains the language models to follow specific instructions and generate appropriate responses. For instruction-tuning, the dataset plays an important role as it provides structured examples of instructions, contexts, and responses, allowing the model to learn how to handle various tasks effectively. Instruction GPT often uses human feedback to refine and improve model performance; however, this lab doesn't cover this aspect.\n",
    "\n",
    "The context and instruction are concatenated to form a single input sequence that the model can understand and use to generate the correct response.\n",
    "\n",
    "#### Context and instruction\n",
    "\n",
    "\t•\tInstruction: A command to specify what the model should do\n",
    "\t•\tContext: Additional information or background required for performing the instruction\n",
    "\t•\tCombined input: The instruction and context combine together into a single input sequence\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review certain examples for various templates:\n",
    "\n",
    "---\n",
    "#### Response template\n",
    "Template: `### Question: {question}\\n ### Answer: {answer}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Question: What is the capital of France?\n",
    "### Answer: Paris\n",
    "```\n",
    "\n",
    "---\n",
    "#### Conversation template\n",
    "\n",
    "Template: `### User: {user_input}\\n ### Bot: {bot_response}`\n",
    "Example:\n",
    "```\n",
    "### User: How are you today?\n",
    "### Bot: I'm doing great, thank you! How can I assist you today?\n",
    "```\n",
    "\n",
    "---\n",
    "#### Instruction and output template\n",
    "\n",
    "Template: `### Instruction: {instruction}\\n ### Output: {output}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Instruction: Translate the following sentence to Spanish: \"Hello, how are you?\"\n",
    "### Output: \"Hola, ¿cómo estás?\"\n",
    "```\n",
    "\n",
    "---\n",
    "#### Completion template\n",
    "\n",
    "Template: `{prompt} ### Completion: {completion}`\n",
    "Example:\n",
    "```\n",
    "Once upon a time in a faraway land, ### Completion: there lived a wise old owl who knew all the secrets of the forest.\n",
    "```\n",
    "\n",
    "#### Summarization template\n",
    "\n",
    "Template: `### Text: {text}\\n ### Summary: {summary}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Text: The quick brown fox jumps over the lazy dog.\n",
    "### Summary: A fox jumps over a dog.\n",
    "```\n",
    "\n",
    "---\n",
    "#### Dialogue template\n",
    "\n",
    "Template: `### Speaker 1: {utterance_1}\\n ### Speaker 2: {utterance_2}\\n ### Speaker 1: {utterance_3}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Speaker 1: Hi, what are you doing today?\n",
    "### Speaker 2: I'm going to the park.\n",
    "### Speaker 1: That sounds fun!\n",
    "```\n",
    "\n",
    "---\n",
    "#### Code generation template\n",
    "\n",
    "Template: `### Task: {task_description}\\n ### Code: {code_output}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Task: Write a function to add two numbers in Python.\n",
    "### Code: def add(a, b):\\n    return a + b\n",
    "```\n",
    "\n",
    "---\n",
    "#### Data analysis template\n",
    "\n",
    "Template: `### Analysis Task: {task_description}\\n ### Analysis: {analysis_output}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Analysis Task: Provide insights from the sales data of Q1 2022.\n",
    "### Analysis: The sales increased by 15% compared to Q4 2021, with the highest growth in the electronics category.\n",
    "```\n",
    "\n",
    "---\n",
    "#### Recipe template\n",
    "\n",
    "Template: `### Recipe Name: {recipe_name}\\n ### Ingredients: {ingredients}\\n ### Instructions: {instructions}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Recipe Name: Chocolate Chip Cookies\n",
    "### Ingredients: Flour, Sugar, Chocolate Chips, Butter, Eggs, Vanilla Extract\n",
    "### Instructions: Mix the dry ingredients, add the wet ingredients, fold in the chocolate chips, and bake at 350°F for 10-12 minutes.\n",
    "```\n",
    "\n",
    "---\n",
    "#### Explanation template\n",
    "\n",
    "Template: `### Concept: {concept}\\n ### Explanation: {explanation}`\n",
    "\n",
    "Example:\n",
    "```\n",
    "### Concept: Photosynthesis\n",
    "### Explanation: Photosynthesis is the process by which green plants use sunlight to synthesize nutrients from carbon dioxide and water.\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    " - Understand the various types of templates including instruction-response, question-answering, summarization, code generation, dialogue, data analysis, and explanation and their applications for fine-tuning large language models (LLMs).\n",
    " - Create and apply different templates to fine-tune LLMs for various tasks.\n",
    " - Format datasets based on the created templates to prepare them for effective model training\n",
    " - Perform instruction fine-tuning using Hugging Face libraries and tools\n",
    " - Apply Low-Rank Adaptation (LoRA) techniques to fine-tune LLMs efficiently\n",
    " - Configure and use the SFTTrainer for supervised fine-tuning of instruction-following models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concepts presented in this lab would apply to the other template formats as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Table of contents__\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Install-required-libraries\">Install required libraries</a></li>\n",
    "            <li><a href=\"#Import-required-libraries\">Import required libraries</a></li>\n",
    "            <li><a href=\"#Define-the-device\">Define the device</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Dataset-description\">Dataset description</a></li>\n",
    "    <li><a href=\"#Model-and-tokenizer\">Model and tokenizer</a></li>\n",
    "    <li><a href=\"#Preprocessing-the-data\">Preprocessing the data</a></li>\n",
    "    <li><a href=\"#Test-the-base-model\">Test the base model</a></li>\n",
    "        <ol>\n",
    "            <li><a href=\"#BLEU-score\">BLEU score</a></li>\n",
    "        </ol>\n",
    "    <li><a href=\"#Perform-instruction-fine-tuning-with-LoRA\">Perform instruction fine-tuning with LoRA</a></li>\n",
    "    <li><a href=\"#Exercises\">Exercises</a></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "### Install required libraries\n",
    "\n",
    "For this lab, use the following libraries, which are __not__ preinstalled in the Skills Network Labs environment. You can install libraries by running the code in the below cell. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq datasets==2.20.0 trl==0.9.6 transformers==4.42.3 peft==0.11.1 tqdm==4.66.4 numpy==1.26.4 pandas==2.2.2 matplotlib==3.9.1 seaborn==0.13.2 scikit-learn==1.5.1 sacrebleu==2.4.2 evaluate==0.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries\n",
    "\n",
    "The following code imports the required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from urllib.request import urlopen\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the device\n",
    "\n",
    "The below code will set your device to 'cuda' if your device is compatible with GPU, otherwise, you can use 'cpu'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset description\n",
    "\n",
    "Use the below sentences to download the CodeAlpaca 20k dataset, a programming code dataset. This code is available [here](https://github.com/sahil280114/codealpaca?tab=readme-ov-file#data-release). The CodeAlpaca dataset contains the following elements:\n",
    "\n",
    "\n",
    "- `instruction`: **str**, describes the task the model should perform. Each of the 20K instructions is unique.\n",
    "- `input`: **str**, optional context or input for the task. For example, when the instruction is \"Amend the following SQL query to select distinct elements\", the input is the SQL query. Around 40% of the examples have an input.\n",
    "- `output`: **str**, the answer to the instruction as generated by text-davinci-003.\n",
    "\n",
    "The following code block downloads the training split from the CodeAlpaca-20k dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7f302e482041f7ac0f031a498ba270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/677 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9eea76eda447f4829e7586ddc2bc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.45M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4696830faeaf4820a507e8c1b897ada8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/20022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output'],\n",
       "    num_rows: 20022\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"lucasmccabe-lmi/CodeAlpaca-20k\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the example in the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Create a JavaScript code snippet to get a list of all the elements in an array with even index.',\n",
       " 'input': 'let arr = [1,2,3,4,5,6];',\n",
       " 'output': 'let evenIndexArr = arr.filter((elem, index) => index % 2 === 0);'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things simple let's just focus on the examples that do not have any `input`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1bef55e4644d9eb214933ecb53c850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/20022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda example: example[\"input\"] == '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original CodeAlpaca dataset may not have been shuffled. The following line indicates how to shuffle a `datasets.arrow_dataset.Dataset()` object with a random seed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output'],\n",
       "    num_rows: 9764\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CodeAlpaca 20k dataset has a training and test set. You can split the original training data into a train and test set by assigning 80% of the data to the training set and 20% to the testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 7811\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 1953\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = dataset_split['train']\n",
    "test_dataset = dataset_split['test']\n",
    "dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a small set of data for the resource limitation\n",
    "# This dataset will be only used for evaluation parts, not for the training\n",
    "tiny_test_dataset=test_dataset.select(range(10))\n",
    "tiny_train_dataset=train_dataset.select(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and tokenizer\n",
    "\n",
    "In this exercise, let's fine-tune the [`opt-350m`](https://huggingface.co/facebook/opt-350m) model from Facebook. A description of this OpenSource model was published [here](https://arxiv.org/abs/2205.01068), and the model was originally made available on [metaseq's Github repository](https://github.com/facebookresearch/metaseq).\n",
    "\n",
    "The below lines load the base model from Hugging Face:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47824bdbb9e6467e835c8719ab1e4602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad94541f649d4dae9d4906b183456f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a235f7b9554b9ebf8a1a8b56574b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model comes with its own tokenizer which you will be loading here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38674b280158404ebd8452a271db7594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487d12aca71e4d16b5bf5bfa572afb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547f4c995a2a475a92872b76c13b5961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7986d0ab8a413592f542224e3bd5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\", padding_side='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the end of sentence (EOS) token. This is a special tokenizer token. Once this token is encountered, the model will stop generating further tokens:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "To perform the fine-tuning, first, preprocess the data by creating functions that generate the prompt.\n",
    "\n",
    "The `formatting_prompts_func` function takes a dataset as input. For every element in the dataset format, the instruction and the output into a template using the format:\n",
    "\n",
    "```\n",
    "### Instruction:\n",
    "Translate the following sentence to Spanish: \"Hello, how are you?\"\n",
    "\n",
    "### Response:\n",
    "\"Hola, ¿cómo estás?</s>\"\n",
    "```\n",
    "\n",
    "_**Note:**_ \n",
    "1. The template provided in this section may differ from the **Instruction and output template** presented in the introduction of this lab. You can replace the  `### Response:` with `### Output:` to generate similar results.\n",
    "\n",
    "2. Introducing the `</s>` end of sentence token at the end of the text informs the model to stop generating text beyond this point.\n",
    "\n",
    "Finally, the `formatting_prompts_func_no_response` function behaves similarly to the `formatting_prompts_func` except the response is not included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Instruction:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Response:\\n{mydataset['output'][i]}</s>\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "def formatting_prompts_func_no_response(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Instruction:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Response:\\n\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block generates the `instructions` (the part of the prompt that does not include the response), the `instructions_with_responses` (the full prompt with the response and `eos` token), and the `expected_outputs`, which are the parts of the `instructions_with_responses` that are between the `instructions` and the `eos` token.\n",
    "\n",
    "To find the `expected_outputs`, tokenize `instructions` and the `instructions_with_responses`. Then, count the number of tokens in `instructions`, and discard the equivalent amount of tokens from the beginning of the tokenized `instructions_with_responses` vector. Finally, discard the final token in `instructions_with_responses`, corresponding to the `eos` token. Decode the resulting vector using the tokenizer, resulting in the `expected_output`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1953/1953 [00:01<00:00, 1387.92it/s]\n"
     ]
    }
   ],
   "source": [
    "expected_outputs = []\n",
    "instructions_with_responses = formatting_prompts_func(test_dataset)\n",
    "instructions = formatting_prompts_func_no_response(test_dataset)\n",
    "for i in tqdm(range(len(instructions_with_responses))):\n",
    "    tokenized_instruction_with_response = tokenizer(instructions_with_responses[i], return_tensors=\"pt\", max_length=1024, truncation=True, padding=False)\n",
    "    tokenized_instruction = tokenizer(instructions[i], return_tensors=\"pt\")\n",
    "    expected_output = tokenizer.decode(tokenized_instruction_with_response['input_ids'][0][len(tokenized_instruction['input_ids'][0])-1:], skip_special_tokens=True)\n",
    "    expected_outputs.append(expected_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the example to view what `instructions` include, `instructions_with_responses`, and `expected_outputs`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## instructions ##############\n",
      "### Instruction:\n",
      "What type of data structure would you use to store key-value pairs in a Python program? Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "############## instructions_with_responses ##############\n",
      "### Instruction:\n",
      "What type of data structure would you use to store key-value pairs in a Python program? Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "The data structure to use for key-value pairs in Python is a dictionary. A dictionary is a data type that consists of key-value pairs, and is denoted by {} in Python. Each key has a unique value associated with it that can be accessed using the key. For example, a dictionary called \"person\" could look like this: \n",
      "\n",
      "person = {'name':'John', 'age': 32} \n",
      "\n",
      "The value of the key \"name\" can be accessed using person['name'] which returns \"John\".</s>\n",
      "\n",
      "############## expected_outputs ##############\n",
      "The data structure to use for key-value pairs in Python is a dictionary. A dictionary is a data type that consists of key-value pairs, and is denoted by {} in Python. Each key has a unique value associated with it that can be accessed using the key. For example, a dictionary called \"person\" could look like this: \n",
      "\n",
      "person = {'name':'John', 'age': 32} \n",
      "\n",
      "The value of the key \"name\" can be accessed using person['name'] which returns \"John\".\n"
     ]
    }
   ],
   "source": [
    "print('############## instructions ##############\\n' + instructions[0])\n",
    "print('############## instructions_with_responses ##############\\n' + instructions_with_responses[0])\n",
    "print('\\n############## expected_outputs ##############' + expected_outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of keeping the instructions as-is, it's beneficial to convert the `instructions` list into a `torch` `Dataset`. The following code defines a class called `ListDataset` that inherits from `Dataset` and creates a `torch` `Dataset` from a list. This class is then used to generate a `Dataset` object from `instructions`: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListDataset(Dataset):\n",
    "    def __init__(self, original_list):\n",
    "        self.original_list = original_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.original_list)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.original_list[i]\n",
    "\n",
    "instructions_torch = ListDataset(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Instruction:\\nWhat type of data structure would you use to store key-value pairs in a Python program? Write corresponding code in Python.\\n\\n### Response:\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions_torch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the base model\n",
    "\n",
    "Let's understand how the base model performs without performing fine-tuning in the model. This may involve response generation from the base, that is from the non-fine-tuned mode. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code defines a text generation pipeline using the `pipeline` class from `transformers`. This pipeline is useful to generate text given by a model and a tokenizer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_pipeline = pipeline(\"text-generation\",\n",
    "                        model=model,\n",
    "                        tokenizer=tokenizer,\n",
    "                        device=device,\n",
    "                        batch_size=2,\n",
    "                        max_length=50,\n",
    "                        truncation=True,\n",
    "                        padding=False,\n",
    "                        return_full_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Note:_** The generation pipeline can generate tokens or text. If```return_tensors=True```, the pipeline returns token IDs; otherwise, it returns words. Additionally, the generation pipeline generates both the instructions *and* the responses by default. However, to assess the model's performance, exclude the generated instructions and focus on the responses. To do this, set ```return_full_text=False```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code leverages the pre-defined generation pipeline to generate outputs using the model. \n",
    "\n",
    "**_Note:_** The code is commented out because it may take a long time for CPU. Instead of generating the raw tokens here, you can load output from this model later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Due to resource limitation, only apply the function on 3 records using \"instructions_torch[:10]\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     pipeline_iterator\u001b[38;5;241m=\u001b[39m \u001b[43mgen_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions_torch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# this is set to 50 due to resource constraint, using a GPU, you can increase it to the length of your choice\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m generated_outputs_base \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m pipeline_iterator:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:262\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(chats, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/base.py:1235\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1232\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1233\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1234\u001b[0m     )\n\u001b[0;32m-> 1235\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/base.py:1161\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1160\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1161\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/pipelines/text_generation.py:349\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1953\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1945\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1946\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1947\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1948\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1949\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1950\u001b[0m     )\n\u001b[1;32m   1952\u001b[0m     \u001b[38;5;66;03m# 14. run beam sample\u001b[39;00m\n\u001b[0;32m-> 1953\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1967\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1968\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1974\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1975\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:2914\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2911\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m stack_model_outputs(outputs_per_sub_batch)\n\u001b[1;32m   2913\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Unchanged original behavior\u001b[39;00m\n\u001b[0;32m-> 2914\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2915\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2917\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2918\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2922\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py:1118\u001b[0m, in \u001b[0;36mOPTForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1115\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1118\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m   1132\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py:884\u001b[0m, in \u001b[0;36mOPTDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    874\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    875\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    876\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         use_cache,\n\u001b[1;32m    882\u001b[0m     )\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 884\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py:525\u001b[0m, in \u001b[0;36mOPTDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    522\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn_layer_norm(hidden_states)\n\u001b[1;32m    524\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 525\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    533\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py:167\u001b[0m, in \u001b[0;36mOPTAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    164\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(key_value_states), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, bsz)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# reuse k, v, self_attention\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, bsz)\n\u001b[1;32m    168\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, bsz)\n\u001b[1;32m    169\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past_key_value[\u001b[38;5;241m0\u001b[39m], key_states], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Due to resource limitation, only apply the function on 3 records using \"instructions_torch[:10]\"\n",
    "    pipeline_iterator= gen_pipeline(instructions_torch[:3], \n",
    "                                    max_length=50, # this is set to 50 due to resource constraint, using a GPU, you can increase it to the length of your choice\n",
    "                                    num_beams=5,\n",
    "                                    early_stopping=True,)\n",
    "\n",
    "generated_outputs_base = []\n",
    "for text in pipeline_iterator:\n",
    "    generated_outputs_base.append(text[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code loads the generated responses for the whole dataset using machine that has access to a fast CUDA-enabled GPU:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VvQRrSqS1P0_GobqtL-SKA/instruction-tuning-generated-outputs-base.pkl')\n",
    "generated_outputs_base = pickle.load(io.BytesIO(urlopened.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the sample responses generated by the base model and the expected responses from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 1: \n",
      "### Instruction:\n",
      "What type of data structure would you use to store key-value pairs in a Python program? Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 1: \n",
      "\n",
      "The data structure to use for key-value pairs in Python is a dictionary. A dictionary is a data type that consists of key-value pairs, and is denoted by {} in Python. Each key has a unique value associated with it that can be accessed using the key. For example, a dictionary called \"person\" could look like this: \n",
      "\n",
      "person = {'name':'John', 'age': 32} \n",
      "\n",
      "The value of the key \"name\" can be accessed using person['name'] which returns \"John\".\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 1: \n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "### Response:\n",
      "Thank you for your question.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 2: \n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 2: \n",
      "\n",
      "The equation ax + b = 0 can be solved by subtracting b from both sides and then dividing both sides by a. This will yield the solution x = -b/a.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 2: \n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 3: \n",
      "### Instruction:\n",
      "Write a CSS rule to set the text size of all elements with the class “big-header” to 24px.\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 3: \n",
      "\n",
      ".big-header {\n",
      "    font-size: 24px;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 3: \n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "### Response:\n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "### Response:\n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "### Response:\n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "### Response:\n",
      "The CSS rule is set to “big-header”.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    print('@@@@@ Instruction '+ str(i+1) +': ')\n",
    "    print(instructions[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Expected response '+ str(i+1) +': ')\n",
    "    print(expected_outputs[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Generated response '+ str(i+1) +': ')\n",
    "    print(generated_outputs_base[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the responses generated by the base model are not up to the mark. Also, the responses have the tendency to extend and repeat the answers until they generate the maximum number of tokens. Later on, you can see that the instruction-tuning can fix both of these issues. First, the instruction fine-tuned model will be able to provide more meaningful responses. Second, because, you appended the `eos` token `<\\s>` to the output, you will teach the model via instruction fine-tuning to not generate responses without bound.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU score\n",
    "\n",
    "Let's set up a metric that compares the generated responses and the expected responses in the test environment. In this lab, let's use the [BLEU score](https://en.wikipedia.org/wiki/BLEU), a metric originally intended to check the quality of translations made by translation models. You can calculate the BLEU scores for individual generated segments by comparing them with a set of expected outputs and average the scores for the individual segments. Depending on the implementation, BLEU scores range from 0 to 1 or from 0 to 100 (as in the implementation used herein), with higher scores indicating a better match between the model generated output and the expected output.\n",
    "\n",
    "_**Note:**_ \n",
    "1. The BLEU score was originally implemented for assessing the quality of translations. However, it may not necessarily be the best metric for instruction fine-tuning in general, but it is nonetheless a useful metric that gives a sense of the alignment between the model generated output and the expected output.\n",
    "2. BLEU scores are very challenging to compare from one study to the next because it is a parametrized metric. As a result, you can employ a variant of BLEU called [SacreBLEU](https://aclanthology.org/W18-6319/) invariant to the metric's parametrization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5d8a203dff4bf8963e6c82e091933a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "results_base = sacrebleu.compute(predictions=generated_outputs_base,\n",
    "                                 references=expected_outputs)\n",
    "\n",
    "print(list(results_base.keys()))\n",
    "print(round(results_base[\"score\"], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SacreBLEU score of 0.4/100 indicates that there is very little alignment between the base model's generated responses and the expected responses for the examples in the test dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform instruction fine-tuning with LoRA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time, let's perform instruction fine-tuning using a parameter-efficient fine-tuning (PEFT) method called low-rank adaptation (LoRA).\n",
    "First, convert the model into a PEFT model suitable for LoRA fine-tuning by defining a `LoraConfig` object from the `peft` library that outlines LoRA parameters, such as the LoRA rank and the target modules. Next, apply LoRA configuration on the model using `get_peft_model()`, which effectively converts `model` into a LoRA `model`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,  # Low-rank dimension\n",
    "    lora_alpha=32,  # Scaling factor\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Modules to apply LoRA\n",
    "    lora_dropout=0.1,  # Dropout rate\n",
    "    task_type=TaskType.CAUSAL_LM  # Task type should be causal language model\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruction fine-tuning using the `SFTTrainer` has the effect of generating the instructions *and* the responses. However, for the purposes of assessing the quality of the generated text, consider only the quality of the response and not the quality of the instruction. For the purposes of calculating the BLEU score, eliminate the length of tokens corresponding to the instruction from the beginning of the tokenized model output. \n",
    "\n",
    "For example, suppose the tokenized instruction had a length of ten, but the generated text had a length of fourteen. Then the tokenized response that was kept for the purposes of calculating the BLEU score was just the four tokens at the end of the tokenized generated text because the first ten tokens represent the model's generation of the tokenized instruction.\n",
    "\n",
    "Although eliminating the first few tokens of the tokenized output worked well for the purposes of calculating BLEU. However, during fine-tuning, the first few tokens won't have an impact on the loss function. You can mask those tokens using -100 by ignoring the value of PyTorch loss functions such as [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). By masking the tokens corresponding to the instruction with -100, only the tokens associated with the response can bear the loss.\n",
    "\n",
    "You can create such a masking manually by defining your own function. However, it is easier to instead use the `DataCollatorForCompletionOnlyLM` class from `trl`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_template = \"### Response:\\n\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pass the `collator`, `DataCollatorForCompletionOnlyLM` object to the data collator into `SFTTrainer`, resulting in the generated instructions without bearing on the loss.\n",
    "\n",
    "To perform the training, first configure our `SFTTrainer`, and create the `SFTTrainer` object by passing to the `collator`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b123309cea54284b0465b5e920bd716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7811 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca36b372e6aa4385b6370c8f6ec9e9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1953 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "training_args = SFTConfig(\n",
    "    output_dir=\"/tmp\",\n",
    "    num_train_epochs=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=2,  # Reduce batch size\n",
    "    per_device_eval_batch_size=2,  # Reduce batch size\n",
    "    max_seq_length=1024,\n",
    "    do_eval=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    args=training_args,\n",
    "    packing=False,\n",
    "    data_collator=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please ignore the above warning.\n",
    "The below comments, runs the trainer, because this would take a long time on the CPU. Therefore, let's not run the trainer here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train the trainer, the `trainer` object would have a state history for every training step. You would be able to access this state history using the below commented out line:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_history_lora = trainer.state.log_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of extracting the state history above, let's load the state history of a model that was instruction fine-tuned to the above specifications on a GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/49I70jQD0-RNRg2v-eOoxg/instruction-tuning-log-history-lora.json')\n",
    "log_history_lora = json.load(io.BytesIO(urlopened.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the training loss for each training step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = [log[\"loss\"] for log in log_history_lora if \"loss\" in log]\n",
    "\n",
    "# Plot the training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to fine-tune the model, the fine-tuned model could be saved using the below commented out line:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_model(\"./instruction_tuning_final_model_lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redefine the text generation pipeline because the model has been changed to the LoRA model. Ignore the warning for the `PeftModelForCausalLM` not being supported for `text-generation`. However, if the PEFT model is supported, the warning is erroneous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "gen_pipeline = pipeline(\"text-generation\", \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer, \n",
    "                        device=device, \n",
    "                        batch_size=2, \n",
    "                        max_length=50, \n",
    "                        truncation=True, \n",
    "                        padding=False,\n",
    "                        return_full_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code generates tokens with the pipeline using the instruction fine-tuned model. Only three records of data are used for demonstration  because generating text is time consuming on CPU:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Due to resource limitation, only apply the function on 3 records using \"instructions_torch[:10]\"\n",
    "    pipeline_iterator= gen_pipeline(instructions_torch[:3],\n",
    "                                max_length=50, # this is set to 50 due to resource constraint, using a GPU, you can increase it to the length of your choice\n",
    "                                num_beams=5,\n",
    "                                early_stopping=True,)\n",
    "generated_outputs_lora = []\n",
    "for text in pipeline_iterator:\n",
    "    generated_outputs_lora.append(text[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_outputs_lora[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the generated texts for the entire dataset from the fine-tuned LoRA model and run on GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/o7uYxe15xvX4CN-6Lr10iA/instruction-tuning-generated-outputs-lora.pkl')\n",
    "generated_outputs_lora = pickle.load(io.BytesIO(urlopened.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some of the responses from the instruction fine-tuned model and the expected responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 1: \n",
      "### Instruction:\n",
      "What type of data structure would you use to store key-value pairs in a Python program? Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 1: \n",
      "\n",
      "The data structure to use for key-value pairs in Python is a dictionary. A dictionary is a data type that consists of key-value pairs, and is denoted by {} in Python. Each key has a unique value associated with it that can be accessed using the key. For example, a dictionary called \"person\" could look like this: \n",
      "\n",
      "person = {'name':'John', 'age': 32} \n",
      "\n",
      "The value of the key \"name\" can be accessed using person['name'] which returns \"John\".\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 1: \n",
      "The type of data structure to use to store key-value pairs in a Python program would be a key-value pair.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 2: \n",
      "### Instruction:\n",
      "Describe a method to solve an equation of the form ax + b = 0. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 2: \n",
      "\n",
      "The equation ax + b = 0 can be solved by subtracting b from both sides and then dividing both sides by a. This will yield the solution x = -b/a.\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 2: \n",
      "\n",
      "A method to solve an equation of the form ax + b = 0 is:\n",
      "\n",
      "def solve(x, y):\n",
      "    return x * y\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@ Instruction 3: \n",
      "### Instruction:\n",
      "Write a CSS rule to set the text size of all elements with the class “big-header” to 24px.\n",
      "\n",
      "### Response:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Expected response 3: \n",
      "\n",
      ".big-header {\n",
      "    font-size: 24px;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "@@@@@ Generated response 3: \n",
      ".big-header {\n",
      "    text-size: 24px;\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    print('@@@@@ Instruction '+ str(i+1) +': ')\n",
    "    print(instructions[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Expected response '+ str(i+1) +': ')\n",
    "    print(expected_outputs[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@ Generated response '+ str(i+1) +': ')\n",
    "    print(generated_outputs_lora[i])\n",
    "    print('\\n\\n')\n",
    "    print('@@@@@@@@@@@@@@@@@@@@')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the base model, you can see that the responses are much better. Additionally, the responses don't extend until the maximum number of tokens are generated.\n",
    "\n",
    "To confirm the responses generated by the instruction fine-tuned model align better with the expected output, let's calculate the SacreBLEU score:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
      "14.7\n"
     ]
    }
   ],
   "source": [
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "results_lora = sacrebleu.compute(predictions=generated_outputs_lora,\n",
    "                                 references=expected_outputs)\n",
    "print(list(results_lora.keys()))\n",
    "print(round(results_lora[\"score\"], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the fine-tuned model achieves a SacreBLEU score of 14.7/100, significantly better than the 0.4/100 achieved by the base model. \n",
    "\n",
    "Let's conclude. The instruction fine-tuned model generates responses that align much better with the expected responses in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Try with another response template (Question-Answering)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `formatting_prompts_response_template` function to format the train_dataset in the Response Template. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template: `### Question: {question}\\n ### Answer: {answer}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here\n",
    "\n",
    "def formatting_prompts_response_template(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Question:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Answer:\\n{mydataset['output'][i]}</s>\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "def formatting_prompts_response_template(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Question:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Answer:\\n{mydataset['output'][i]}</s>\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `formatting_prompts_response_template_no_response` function to format the `test_dataset` in the Response Template, excluding the response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template: `### Question: {question}\\n ### Answer: `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here\n",
    "\n",
    "def formatting_prompts_response_template_no_response(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Question:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Answer:\\n\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "def formatting_prompts_response_template_no_response(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Question:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Answer:\\n\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Try with another LLM (EleutherAI/gpt-neo-125m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EleutherAI/gpt-neo-125m is a smaller variant of the GPT-Neo family of models developed by EleutherAI. With 125 million parameters, it is designed to be computationally efficient while still providing robust performance for various natural language processing tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and load the `EleutherAI/gpt-neo-125m` model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9800471acc9d470c946264c9f864dce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbdc8054b6a44c8a412d674df06b263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031e8be35cb6445c862994156d6dbc88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0403dfc105104184a830d9dd9d7f8b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146f49ec70e64d2495f7c119c4691523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6baba8e26b452aae1a3e20ac733980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d43f3d1036d4b7bab0abd0f91e219e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f28f55317ea4e7aa542986675fb1642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#write your code here\n",
    "\n",
    "model_name = \"EleutherAI/gpt-neo-125m\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "model_name = \"EleutherAI/gpt-neo-125m\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize LoRA Configuration:\n",
    "\n",
    "- r: 8 (Low-rank dimension)\n",
    "- lora_alpha: 16 (Scaling factor)\n",
    "- target_modules: [\"q_proj\", \"v_proj\"] (Modules to apply LoRA)\n",
    "- lora_dropout: 0.1 (Dropout rate)\n",
    "- task_type: TaskType.CAUSAL_LM (Task type should be causal language model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Low-rank dimension\n",
    "    lora_alpha=16,  # Scaling factor\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Modules to apply LoRA\n",
    "    lora_dropout=0.1,  # Dropout rate\n",
    "    task_type=TaskType.CAUSAL_LM  # Task type should be causal language model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Low-rank dimension\n",
    "    lora_alpha=16,  # Scaling factor\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Modules to apply LoRA\n",
    "    lora_dropout=0.1,  # Dropout rate\n",
    "    task_type=TaskType.CAUSAL_LM  # Task type should be causal language model\n",
    ")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply LoRA Configuration to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code here\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPTNeoForCausalLM(\n",
       "      (transformer): GPTNeoModel(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(2048, 768)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPTNeoBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPTNeoAttention(\n",
       "              (attention): GPTNeoSelfAttention(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "                (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPTNeoMLP(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for the solution</summary>\n",
    "\n",
    "```python\n",
    "model = get_peft_model(model, lora_config)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You have completed the lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Wojciech \"Victor\" Fulmyk](https://www.linkedin.com/in/wfulmyk) is a Data Scientist and a PhD Candidate in Economics at the University of Calgary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Fateme Akbari](https://www.linkedin.com/in/fatemeakbari/) is a Ph.D. candidate in Information Systems at McMaster University with demonstrated research experience in Machine Learning and NLP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Joseph Santarcangelo](https://author.skills.network/instructors/joseph_santarcangelo) has a Ph.D. in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[Supervised Fine-tuning Trainer](https://huggingface.co/docs/trl/main/en/sft_trainer)\n",
    "\n",
    "[Finetuning To Follow Instructions](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch07/01_main-chapter-code/ch07.ipynb)\n",
    "\n",
    "[Finetuning with LoRA -- A Hands-On Example](https://lightning.ai/lightning-ai/studios/code-lora-from-scratch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{## Change Log|Date (YYYY-MM-DD)|Version|Changed By|Change Description||-|-|-|-||2024-07-18|1.0|Wojciech \"Victor\" Fulmyk|Lab Written||2024-07-25|2.0|Fateme Akbari|Bugs Fixed||2024-07-31|3.0|Bhavika Chhatbar|ID reviewed|}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© Copyright IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "280a2cf79e2287085899526a711a657e3abe91f52fd641be6356c1ef9f2bafbd"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

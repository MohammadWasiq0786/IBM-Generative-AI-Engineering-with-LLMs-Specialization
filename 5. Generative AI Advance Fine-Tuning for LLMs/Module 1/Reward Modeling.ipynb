{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward Modeling\n",
    "Imagine that you're working as a machine learning engineer for a large technology company that wants to integrate advanced language models into its suite of AI-powered products. Your task is to evaluate and select the best large language model (LLM) that can understand and follow complex instructions, improve the quality of automated customer service, and generate high-quality responses.\n",
    "\n",
    "However, simply choosing a powerful LLM isn't enough. To truly excel in these tasks, the model should be fine-tuned to align with specific goals and criteria. This is where reward models come into the picture. By training a reward model, you can guide the LLM to prioritize certain behaviors, ensuring it generates responses that not only meet technical standards but also align with the company's values and objectives.\n",
    "\n",
    "In this hands-on lab, you dive into the process of creating and training a reward model by using the transformer reinforcement learner (trl) library from Hugging Face. You learn how to set up the environment, define the rewards that shape the model's behavior, and fine-tune the LLM to perform with precision. This project equips you with the skills to implement reward models in real-world applications, enhancing the effectiveness and quality of AI-powered products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    </ul>\n",
    "    <li><a href=\"#Setup\">Setup</a></li>\n",
    "    <ul>\n",
    "        <li><a href=\"#Installing-required-libraries\">Installing required libraries</a></li>\n",
    "        <li><a href=\"#Importing-required-libraries\">Importing required libraries</a></li>\n",
    "        <li><a href=\"#Defining-helper-functions\">Defining helper functions</a></li>\n",
    "    </ul>\n",
    "    <li><a href=\"#Dataset\">Data set</a></li>\n",
    "    <ul>\n",
    "        <li><a href=\"#Purpose\">Purpose</a></li>\n",
    "        <li><a href=\"#Applications\">Applications</a></li>\n",
    "        <li><a href=\"#Dataset-features\">Data set features</a></li>\n",
    "    </ul>\n",
    "    <li><a href=\"#Model-and-tokenizer-Setup\">Model and tokenizer setup</a></li>\n",
    "    <li><a href=\"#Preprocessing\">Preprocessing</a></li>\n",
    "    <ul>\n",
    "        <li><a href=\"#LoRA-configuration\">LoRA configuration</a></li>\n",
    "        <li><a href=\"#Training-arguments\">Training arguments</a></li>\n",
    "        <li><a href=\"#Reward-Trainer\">Reward trainer</a></li>\n",
    "    </ul>\n",
    "    <li><a href=\"#Evaluating-the-model\">Evaluating the model</a></li>\n",
    "    <li><a href=\"#Exercise\">Exercise</a></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "After completing this lab, you are able to:\n",
    "\n",
    "- Understand the concept of reward modeling in machine learning\n",
    "- Explore and preprocess a data set for reward modeling tasks\n",
    "- Set up and configure a GPT-2 model for sequence classification\n",
    "- Tokenize and prepare text data for model training\n",
    "- Evaluate model performance using pairwise comparison of responses\n",
    "- Apply preprocessing and evaluation techniques to different subsets of data\n",
    "- Understand important concepts related to transformers and reward modeling\n",
    "- Implement special tokens in the tokenizer and configure the model accordingly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Installing required libraries\n",
    "Before you start, make sure that you have all of the necessary libraries installed. You can run the following commands to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.25.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: trl in /opt/conda/lib/python3.11/site-packages (0.9.6)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from trl) (2.4.1)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.11/site-packages (from trl) (4.42.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.18.2 in /opt/conda/lib/python3.11/site-packages (from trl) (1.26.4)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (from trl) (0.34.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (from trl) (2.20.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.11/site-packages (from trl) (0.8.11)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (0.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (4.66.4)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (13.9.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate->trl) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.31.0->trl) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.31.0->trl) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.31.0->trl) (2024.6.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2024.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (2.20.0)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (0.25.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.42.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft) (2.4.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft) (4.42.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.34.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.25.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting click (from nltk)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk) (4.66.4)\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.11/site-packages (from rouge_score) (1.16.0)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=449c43a11ba56680d4a9a4392d7a64b395ee3d6c7e067748360cf9275b678e87\n",
      "  Stored in directory: /home/jupyterlab/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: click, absl-py, nltk, rouge_score\n",
      "Successfully installed absl-py-2.1.0 click-8.1.7 nltk-3.9.1 rouge_score-0.1.2\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.42.3)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m876.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n",
      "Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.42.3\n",
      "    Uninstalling transformers-4.42.3:\n",
      "      Successfully uninstalled transformers-4.42.3\n",
      "Successfully installed tokenizers-0.20.0 transformers-4.45.1\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (0.11.1)\n",
      "Collecting peft\n",
      "  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft) (24.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft) (2.4.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft) (4.45.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.34.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.25.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (0.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.13.0-py3-none-any.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.11.1\n",
      "    Uninstalling peft-0.11.1:\n",
      "      Successfully uninstalled peft-0.11.1\n",
      "Successfully installed peft-0.13.0\n",
      "Collecting bitsandbytes==0.43.1\n",
      "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from bitsandbytes==0.43.1) (2.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from bitsandbytes==0.43.1) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.11/site-packages (from torch->bitsandbytes==0.43.1) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.43.1) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->bitsandbytes==0.43.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->bitsandbytes==0.43.1) (1.3.0)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.1\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install trl\n",
    "!pip install datasets huggingface_hub\n",
    "!pip install transformers\n",
    "!pip install peft\n",
    "!pip install nltk rouge_score\n",
    "!pip install --upgrade transformers\n",
    "!pip install --upgrade peft\n",
    "!pip install bitsandbytes==0.43.1\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, TrainingArguments\n",
    "from peft import LoraConfig, TaskType\n",
    "from transformers import TrainingArguments\n",
    "from trl import RewardTrainer\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Disable warnings for a cleaner notebook or console experience\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(data, file_path):\n",
    "    \"\"\"\n",
    "    Save a dictionary to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        data (dict): The dictionary to save.\n",
    "        file_path (str): The path to the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "    print(f\"Data successfully saved to {file_path}\")\n",
    "    \n",
    "    \n",
    "def load_from_json(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The data loaded from the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data set\n",
    "\n",
    "In this section, you load a data set that is used for training the reward model. In this lab, you use the Dahoas/synthetic-instruct-gptj-pairwise data set from Hugging Face, a synthetic data set that is designed for training and evaluating instruction-following models. This data set includes pairs of prompts and responses, where one response is preferred over the other. The primary use case is to train models to distinguish between better and worse responses, essential for tasks like reinforcement learning with human feedback (RLHF).\n",
    "\n",
    "### Purpose\n",
    "\n",
    "This data set helps train models for better understanding and following instructions by learning from pairs of good and bad responses. This is particularly useful for improving the quality of generated responses in dialogue systems and other AI applications that require understanding and generating natural language instructions.\n",
    "\n",
    "### Applications\n",
    "- **Reinforcement learning**: Enhancing models to prefer better responses based on feedback\n",
    "- **Fine-tuning language models**: Improving the performance of models on instruction-following tasks\n",
    "- **Evaluation**: Assessing the ability of models to distinguish between high- and low-quality responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800106e9612147838d4d3f596b571ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22be3e0c026b4603a5712f38aa447e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/18.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06936b3d56c54916b19e04034f9bb385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/33143 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected'],\n",
      "        num_rows: 33143\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the Dahoas/synthetic-instruct-gptj-pairwise dataset \n",
    "dataset = load_dataset(\"Dahoas/synthetic-instruct-gptj-pairwise\")\n",
    "# Display the dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set features\n",
    "\n",
    "To get a better understanding of the data set, let's inspect a few samples. First, print out the `prompt`, `chosen`, and `rejected` responses for the first 10 examples in the training set. This gives an insight into the type of data on which you are working and how it is structured.\n",
    "\n",
    "```Prompt:``` A text prompt that the model should respond to\n",
    "\n",
    "```Chosen:``` The preferred response to the prompt\n",
    "\n",
    "```Rejected:``` The less preferred response to the prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt\n",
      "I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs. \n",
      "\n",
      "chosen\n",
      "Sure! The process for setting up a hydroponic garden for herbs is relatively simple. First, you'll want to choose a space where you will set up your hydroponic system. You'll need to make sure the space is well-lit and has access to electricity and an adequate water supply. Next, you'll need to choose the type of hydroponic system you want to use. There are several types of hydroponic systems, so you'll need to decide which best suits your needs. Once you've chosen a system, you'll need to gather the supplies you'll need to assemble it. This includes things like pumps, growing trays, grow lights, and nutrients. Once you've assembled the system, you'll need to add your choice of herbs to the system. Lastly, you'll need to monitor and adjust the system as needed to ensure your herbs are getting the correct amount of light, water, and nutrients. \n",
      "\n",
      "rejected\n",
      "How do I store a bagels for eating at a later date?\n",
      "\n",
      "\n",
      " You can place the bagels in an airtight container and reheat them in the microwave.  Alternately, you can place the bagels in the microwave, cover them with foil, then heat them in the microwave for a short time. \n",
      "\n",
      "---------------------------\n",
      "\n",
      "prompt\n",
      "What type of wine goes best with steak. \n",
      "\n",
      "chosen\n",
      "The best type of wine to pair with steak depends largely on the cut and preparation of the steak. Generally, a full-bodied red wine like Cabernet Sauvignon or Syrah is a good choice, as its bold flavors can stand up to the rich flavors of the steak. Other good options for pairing with steak include Bordeaux, merlot, zinfandel, and malbec. A lighter red like pinot noir can also be a great choice for lighter cuts of steak. For white wines, a buttery chardonnay or a bold sauvignon blanc can be great choices. A sparkling wine, such as Prosecco, can also go well with steak. \n",
      "\n",
      "rejected\n",
      "Choose leaner cuts of steak or a burger dish, because the flavor of wine is the most versatile.  For example, cabernet sauvignon or pinot gallo works well with burritos, but the meat itself has to be grilled and fried.  \n",
      "2.  Pour a good quality dry white wine that’s moderately young.  Chardonnay or far-lauter is also nice for steak.  \n",
      "3.  Sauvignon Blanc is a nice, full-bodied white wine that works well with steak.\n",
      "4.  Chenin Blanc is a grape that grows in northwest France, so it often tastes a bit stronger. \n",
      "\n",
      "---------------------------\n",
      "\n",
      "prompt\n",
      "How do I know if this is a good investment. \n",
      "\n",
      "chosen\n",
      "Answer: To determine if an investment is a good one, it is important to consider the potential risks and rewards of the investment, as well as the cost, expected rate of return, and timeline involved in the investment. Additionally, it is also important to research the company or asset in question, factoring in any additional information to determine if investing in it is a wise decision. \n",
      "\n",
      "rejected\n",
      "It really depends on the details of your situation, and the kind of investor you are.  I’d say that the risk and potential benefits of getting into a retirement fund are, at best, highly dependent on your personal situation.  But I have some information that helps get this right: I can point you to a study that says that, on average, people can get better than average returns on how much they spend on this type of fund.  The risks of this fund are estimated to be. \n",
      "\n",
      "---------------------------\n",
      "\n",
      "prompt\n",
      "Please provide me with some financial advice. \n",
      "\n",
      "chosen\n",
      "Some financial advice is to always pay yourself first. Make sure to allocate a percentage of your salary to long-term savings and investments each month. Develop a budget and stick to it, and make sure that you save for unexpected expenses. Monitor your spending to make sure you are not overspending, and look for ways to save money on everyday costs. Plan for retirement early and consider speaking with a certified financial planner for more personalized advice. \n",
      "\n",
      "rejected\n",
      "My annual income was $24,051. I would like to make at least $40,000.00.\n",
      "\n",
      "\n",
      " I can definitely help you with that!  Let me just explain a few simple options that might be useful:\n",
      "\n",
      "1.  You could buy stocks to invest money into your 401k.  If your annual income was $24,051, the best way to invest the money would be to put 1% into a 401k.  \n",
      "2.  Or you could invest it into a 401k with a higher annual percentage.  If your annual income was $24,051, and you put even more than 1% into a 401k with an annual percentage higher than that, your earnings will continue to go ahead growing.  \n",
      "3.  Or you could try a mixture of stocks and bonds, that’s called a “bonds fund”.  It’s kind of like a savings account for the bonds.  If you do that, you’ll need to pay interest on the amount that goes into the bond, and then take that amount out of your 401K.  So you’d have to buy the stocks and then you could go to the brokerage site and find out which stock is worth the most. \n",
      "\n",
      "---------------------------\n",
      "\n",
      "prompt\n",
      "What kind of safety devices do I need to install in my house. \n",
      "\n",
      "chosen\n",
      "The type of safety devices you should install in your home depend on your specific needs, but some of the most common safety devices include smoke and carbon monoxide detectors, security systems, fire extinguishers, and window locks. Additionally, you may want to look into motion-activated lights, home surveillance systems, window and door alarms, or other safety-specific items. \n",
      "\n",
      "rejected\n",
      "There are actually several different types of safety devices that you could install, which are known as “Safety devices”.  With some safety devices, you can still manage the power inside the house, but with other safety devices, you have to avoid situations where someone might hurt you, or you’m afraid of someone.  Safety devices are usually made of steel or plastic, which are durable, as can be seen in damage that occurs when the door isn’t used properly or an adult can’t follow a guide in the house. \n",
      "\n",
      "---------------------------\n",
      "\n",
      "prompt\n",
      "How do I interpret the results of my blood test. \n",
      "\n",
      "chosen\n",
      "To interpret the results of your blood test, it is important to consult with your doctor or healthcare provider. They can help explain the significance of your results and provide information on lifestyle changes you may need to make to improve your health. Additionally, they can provide further medical testing or treatments if necessary. \n",
      "\n",
      "rejected\n",
      "When your blood tests show that you have a low platelet count, you mean that you have a reduced ability to clotting the blood.  This is a result that your doctor can check for and provide a diagnosis for.\n",
      "2. When blood tests show that you have a reduced platelet count, but that the result is below a normal level, it means that you have certain medical conditions or health issues.  Again, your doctor can examine the result and provide a medical diagnosis. \n",
      "\n",
      "---------------------------\n",
      "\n",
      "prompt\n",
      "I'm having trouble finding the perfect job. What resources can help me. \n",
      "\n",
      "chosen\n",
      "Start by making a list of your interests and skills, then use job search websites such as Indeed or Glassdoor to search for openings that match your criteria. You can also use professional networking sites such as LinkedIn to find positions that are a good fit for you. Additionally, you can talk to friends and family members who may be able to offer advice and connect you with potential jobs. Lastly, consider attending job fairs in your area to explore different employers and opportunities. \n",
      "\n",
      "rejected\n",
      "st \n",
      "2nd \n",
      "3th \n",
      "5th \n",
      "6th \n",
      "7th \n",
      "8th \n",
      "9th \n",
      "10th \n",
      "11th\n",
      "12th\n",
      "13th \n",
      "13th\n",
      "14th\n",
      "\n",
      "So after, how does?\n",
      "\n",
      "-5th-6th-7th>...\n",
      "\n",
      "What was 6th and 7th?\n",
      "\n",
      "-2th-3rd>...\"\n",
      "\n",
      "What was 2th and 3rd?\n",
      "\n",
      "-1st-2nd-3rd>...\n",
      "\n",
      "What was 2th and 3rd?\n",
      "\n",
      "-1st-2nd-3rd>...\n",
      "\n",
      "What was 3rd?\n",
      "\n",
      "\n",
      " -2th-3rd>, 3th, 5th, 6th, 7th>...\n",
      "\n",
      "What was 4th?\n",
      "A -1st and 2nd together?\n",
      "A -2x, 3rd?, 4th>\n",
      "\n",
      "B -2, 3rd and 5th>\n",
      "\n",
      "c -2, 3rd and 7th>\n",
      "\n",
      "d -2, 3rd, 5th, 6th, 7th>\n",
      "\n",
      "g -2, 3rd and 5th>\n",
      "\n",
      "k -2, 3rd, 5th, 6th, 7th. \n",
      "\n",
      "---------------------------\n",
      "\n",
      "prompt\n",
      "What does a roux look like. \n",
      "\n",
      "chosen\n",
      "A roux is a mixture of fat, such as butter or oil, and flour that is cooked together until it is a smooth paste and used as a base for sauces and soups. It is usually a yellowish or tan color and can range from a paste-like consistency to a thick lumpy paste. \n",
      "\n",
      "rejected\n",
      "Yes, it is basically a paste.   \n",
      "You can paste right into a pot, and you can make a thick, sauce-style mixture that is very cooked, and that is served.  But on the end, it will start with a bunch of cooked vegetables and a mixture of gravy.  It can also be served with potatoes, and some of the best sauce for potatoes is a mixture called a roux, which is usually served on corn, with a sauce on the end.  You can also make a chandoull paste, and that is somewhat similar.  There’s lots of stuff in a pan that goes on top of the sauce, such as gravy-shaped pieces.  But the gravy itself is made by cooking some of the vegetables down in a pan and adding a mixture of stock to the pan.  That mixture is called a roux, and it is a combination of cooked vegetable fragments, mixed with the stock.  In some cases, it can also be whipped up and served a bit like a a paste, so the point is to avoid making a cooked paste.  It can also be cooked and served on the side.  But the gravy would still be made by the cooking of the vegetables. \n",
      "\n",
      "---------------------------\n",
      "\n",
      "prompt\n",
      "How to make money online. \n",
      "\n",
      "chosen\n",
      "One way to make money online is to start a business offering services or selling products online. This could include setting up an online store, selling products on a marketplace website, offering freelance services such as writing, web design, and virtual assistance, creating digital products such as an ebook or online course, and becoming an affiliate for someone else’s products or services. Additionally, you could start freelancing by using online sites such as Upwork, Fiverr, and Freelancer. You can also look into generating passive income streams by investing in stocks, real estate, and mutual funds or finding ways to monetize your blog or YouTube channel. \n",
      "\n",
      "rejected\n",
      "Make money online by blogging, social media, or becoming an Amazon affiliate. \n",
      "\n",
      "---------------------------\n",
      "\n",
      "prompt\n",
      "What are some job options for engineering majors. \n",
      "\n",
      "chosen\n",
      "Some job options for engineering majors include aerospace engineer, civil engineer, computer engineer, electrical engineer, mechanical engineer, software engineer, chemical engineer, biomedical engineer, and environmental engineer. \n",
      "\n",
      "rejected\n",
      "Those are in the engineering supply stores, and they’re called “Engineers. \n",
      "\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):    \n",
    "    print('prompt')\n",
    "    print(dataset[\"train\"][i]['prompt'],'\\n')\n",
    "    \n",
    "    print('chosen')\n",
    "    print(dataset[ 'train'][i]['chosen'],'\\n')\n",
    "\n",
    "    print('rejected')\n",
    "    print(dataset[ 'train'][i]['rejected'],'\\n')\n",
    "    print('---------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and tokenizer setup\n",
    "In this section, you set up the tokenizer and the model for training. You can use the GPT-2 model for sequence classification, which helps in determining the quality of responses.\n",
    "\n",
    "Next, specify the model name or path as \"gpt2\". To initialize the tokenizer and model, use `GPT2Tokenizer.from_pretrained` and `GPT2ForSequenceClassification.from_pretrained`, respectively, with `num_labels` set to 1 for ranking (a numerical score value). To handle padding, set the `pad_token` of the tokenizer to be the same as the `eos_token` (end-of-sequence token). Similarly, configure the model to use the `eos_token_id` as the `pad_token_id`. This setup ensures that the tokenizer and model are correctly initialized and prepared for sequence classification tasks with GPT-2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e822ef28374c0eb414b4578d6ab2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8d965772a84803bec0434975cfbca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22aee7d38e3447d099f66e2929b470a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa82992ecc2645889d3e01ebea9f09d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1f3d1734274afd8e6b7b121661ba37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fd440d113443ae90a58fe62577bbde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define the model name or path\n",
    "model_name_or_path = \"gpt2\"\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_name_or_path, num_labels=1)\n",
    "\n",
    "# Add special tokens if necessary\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "# Define the maximum length\n",
    "max_length = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, preprocess the data set for training. Then combine the prompt with the chosen and rejected responses into a format suitable for input into the model. This process helps create clear input-output pairs for the model to learn from.\n",
    "\n",
    "`Lambda Function`: Define a lambda function `get_res` that takes the data set and a response type (chosen or rejected) and combines the prompt with the respective response. Each entry is formatted as a dialogue between \"Human\" and \"Assistant\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_res=lambda dataset,res:[  \"\\n\\nHuman: \"+prompt + \"\\n\\nAssistant: \"+resp for prompt, resp in zip(dataset[\"train\"][\"prompt\"], dataset[\"train\"][res])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Chosen Samples`: Apply the `get_res` function to create a list of chosen samples.\n",
    "\n",
    "`Rejected Samples`: Similarly, create a list of rejected samples using the same function.\n",
    "\n",
    "After applying the function,  you get the following results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen \n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: Sure! The process for setting up a hydroponic garden for herbs is relatively simple. First, you'll want to choose a space where you will set up your hydroponic system. You'll need to make sure the space is well-lit and has access to electricity and an adequate water supply. Next, you'll need to choose the type of hydroponic system you want to use. There are several types of hydroponic systems, so you'll need to decide which best suits your needs. Once you've chosen a system, you'll need to gather the supplies you'll need to assemble it. This includes things like pumps, growing trays, grow lights, and nutrients. Once you've assembled the system, you'll need to add your choice of herbs to the system. Lastly, you'll need to monitor and adjust the system as needed to ensure your herbs are getting the correct amount of light, water, and nutrients.\n",
      "rejected \n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: How do I store a bagels for eating at a later date?\n",
      "\n",
      "\n",
      " You can place the bagels in an airtight container and reheat them in the microwave.  Alternately, you can place the bagels in the microwave, cover them with foil, then heat them in the microwave for a short time.\n"
     ]
    }
   ],
   "source": [
    "chosen_samples=get_res( dataset,'chosen')\n",
    "rejected_samples=get_res( dataset,'rejected')\n",
    "print('chosen',chosen_samples[0])\n",
    "print('rejected',rejected_samples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate the training process, create new columns in the data set that combine the prompt with chosen and rejected responses. This combination helps in evaluating the responses in a structured dialogue format.\n",
    "\n",
    "**Function definition**: Define a function `add_combined_columns` that takes an example (a single data point) and adds two new columns:\n",
    "- `prompt_chosen`: Combines the `prompt` with the `chosen` response in the same labeled format.\n",
    "- `prompt_rejected`: Combines the `prompt` with the `rejected` response in the same labeled format.\n",
    "\n",
    "**Apply function**: The `map` method is used to apply this function to each example in the training split of the data set. This method iterates over all the examples and modifies them in place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2044f7a8e642e5bba87f6615de97f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33143 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to combine 'prompt' with 'chosen' and 'rejected' responses\n",
    "def add_combined_columns(example):\n",
    "    # Combine 'prompt' with 'chosen' response, formatting it with \"Human:\" and \"Assistant:\" labels\n",
    "    example['prompt_chosen'] = \"\\n\\nHuman: \" + example[\"prompt\"] + \"\\n\\nAssistant: \" + example[\"chosen\"]\n",
    "    \n",
    "    # Combine 'prompt' with 'rejected' response, formatting it with \"Human:\" and \"Assistant:\" labels\n",
    "    example['prompt_rejected'] = \"\\n\\nHuman: \" + example[\"prompt\"] + \"\\n\\nAssistant: \" + example[\"rejected\"]\n",
    "    \n",
    "    # Return the modified example\n",
    "    return example\n",
    "\n",
    "# Apply the function to each example in the 'train' split of the dataset\n",
    "dataset['train'] = dataset['train'].map(add_combined_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using pretrained transformers for classification tasks, understanding the maximum sequence length supported by the model is crucial, as pretrained transformers have a fixed maximum token length, for example, GPT-2 has 1024 tokens. Inputs longer than this are truncated, potentially losing important information. So a function is written to determine the max length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(samples)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_len= lambda samples: max([len(sample) for sample in samples])\n",
    "get_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rejected samples length 5011\n",
      "chosen samples length 3167\n"
     ]
    }
   ],
   "source": [
    "print(\"rejected samples length\",get_max_len(rejected_samples))\n",
    "print(\"chosen samples length\",get_max_len(chosen_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you might want to identify samples shorter than a specified maximum length. This can be useful for filtering or handling special cases during preprocessing.\n",
    "\n",
    "The lambda function `find_short` takes a data set and a maximum length (`max_length`) as input. It uses a list comprehension to iterate over each example in the data set, enumerating both the index and the (chosen, rejected) pair. It zips `prompt_chosen` and `prompt_rejected` to pair each chosen response with its corresponding rejected response. For each pair, it checks if the length of either `chosen` or `rejected` is less than the specified `max_length`. If the condition is met, the index of that pair is included in the resulting list. The resulting list contains the index of all examples where either `prompt_chosen` or `prompt_rejected` is shorter than the specified `max_length`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_short = lambda dataset, max_length: [\n",
    "    i for i, (chosen, rejected) in enumerate(zip(dataset['prompt_chosen'], dataset['prompt_rejected']))\n",
    "    if len(chosen) < max_length or len(rejected) < max_length\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that your data set only includes samples that meet the required length criteria, filter out any samples that are shorter than the specified `max_length`. This step is important for maintaining consistency in the input data for the model.\n",
    "\n",
    "Now, use the GPT-2 model for classification with a max length of 1024. First, set the maximum length (`max_length`) to 1024. The `find_short` function is then called with the training data set (`dataset['train']`) and this maximum length as arguments to find indices of examples where either `prompt_chosen` or `prompt_rejected` is shorter than the specified `max_length`. The resulting index (`subset_indices`) is used to create a subset of the training data set by selecting only the examples at these indices. The training data set (`dataset['train']`) is updated to this subset, and the `subset_indices` are returned or printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length=1024\n",
    "subset_indices=find_short (dataset['train'], max_length)\n",
    "dataset['train'] = dataset['train'].select(subset_indices)\n",
    "subset_indices[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " The ```preprocess_function``` tokenizes the ```prompt_chosen``` and ```prompt_rejected``` keys, which are crucial for the RewardTrainer. The ```chosen``` key represents the preferred responses, while the ```rejected``` key represents the less preferred responses.\n",
    " Tokenizing these keys allows the model to process and understand the differences between high-quality and low-quality responses. By providing both ```chosen``` and ```rejected``` inputs, the RewardTrainer can learn to distinguish and prioritize better responses, which is essential for training models to follow instructions effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a preprocessing function to tokenize the 'prompt_chosen' and 'prompt_rejected' keys\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the 'prompt_chosen' text with truncation and padding to the maximum length\n",
    "    tokenized_chosen = tokenizer(examples['prompt_chosen'], truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "    \n",
    "    # Tokenize the 'prompt_rejected' text with truncation and padding to the maximum length\n",
    "    tokenized_rejected = tokenizer(examples['prompt_rejected'], truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "    \n",
    "    # Return the tokenized inputs as a dictionary\n",
    "    return {\n",
    "        \"input_ids_chosen\": tokenized_chosen[\"input_ids\"],  # Token IDs for 'chosen' responses\n",
    "        \"attention_mask_chosen\": tokenized_chosen[\"attention_mask\"],  # Attention masks for 'chosen' responses\n",
    "        \"input_ids_rejected\": tokenized_rejected[\"input_ids\"],  # Token IDs for 'rejected' responses\n",
    "        \"attention_mask_rejected\": tokenized_rejected[\"attention_mask\"],  # Attention masks for 'rejected' responses\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `input_ids_chosen` and `input_ids_rejected` fields contain the token IDs for the `chosen` and `rejected` responses, respectively, which are the numerical representations of the text used by the model. The `attention_mask_chosen` and `attention_mask_rejected` fields contain the attention masks for the `chosen` and `rejected` responses, respectively, which indicates tokens that should be attended to (1) and should ignore (0). These fields are crucial for the `RewardTrainer` because they provide the necessary tokenized inputs and attention masks for both the preferred and less preferred responses. By comparing the token IDs and attention patterns of the `chosen` and `rejected` responses, the `RewardTrainer` can distinguish between high- and low-quality responses, thereby improving the model's ability to prioritize better responses in instruction-following tasks.\n",
    "\n",
    "You can apply the ```reprocess_function``` to one sample:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example=preprocess_function(dataset['train'][0])\n",
    "example.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a dictionary with 'chosen' and 'rejected' samples from the training data set. This dictionary is created to make it easier to validate the model later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_str={'chosen': [sample for sample in dataset['train'] ['prompt_chosen']], 'rejected':[sample for sample in dataset['train'] ['prompt_rejected']]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code applies the preprocess_function to each example in the training data set using the map method, which tokenizes the ```prompt_chosen``` and ```prompt_rejected``` texts. The `batched = True` parameter allows the function to process multiple examples at once, improving efficiency. Additionally, the `remove_columns` parameter specifies a list of columns (```prompt```, ```chosen```, ```rejected```, ```prompt_chosen```, ```prompt_rejected```) to be removed from the data set after processing. This ensures that only the tokenized inputs and attention masks generated by `preprocess_function` are retained, simplifying the data set structure and making it more suitable for model training and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1202ab0ede7640c4ba88bd9a3da465ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['train'] = dataset['train'].map(preprocess_function, batched=True, remove_columns=['prompt',\"chosen\", \"rejected\",'prompt_chosen', 'prompt_rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only columns left are the tokens and masks indexes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['input_ids_chosen',\n",
       "  'attention_mask_chosen',\n",
       "  'input_ids_rejected',\n",
       "  'attention_mask_rejected']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, split the data set into training and testing data sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = dataset['train'].train_test_split(test_size=0.2)\n",
    "\n",
    "# Create a DatasetDict to hold train and test splits\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': split_dataset['train'],\n",
    "    'test': split_dataset['test'],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## LoRA configuration\n",
    "Now that the training data set is ready, you use the pretrain transformer model to start training. However, it is advisable to use a more efficient LoRA configuration for the model. Now, define the LoRA configuration and training arguments.\n",
    "\n",
    "First, initialize a `LoraConfig` configuration for low-rank adaptation (LoRA) in a sequence classification task. The configuration is created by using the `LoraConfig` class from the `peft` library and specifies several parameters:\n",
    "\n",
    "- **task_type=TaskType.SEQ_CLS**: Specifies the type of task, that is, the sequence classification for this lab.\n",
    "- **inference_mode=False**: Indicates that the configuration is for training mode rather than inference.\n",
    "- **r=8**: Sets the rank of the LoRA matrices.\n",
    "- **lora_alpha=32**: Sets the alpha value for scaling the LoRA matrices.\n",
    "- **lora_dropout=0.1**: Specifies the dropout rate for the LoRA layers, helping to prevent overfitting.\n",
    "- **target_modules=[\"attn.c_attn\", \"attn.c_proj\"]**: Lists the specific attention layers in the model that will be adapted using LoRA. This includes the \"attn.c_attn\" and \"attn.c_proj\" modules.\n",
    "\n",
    "This configuration is useful for applying LoRA to the specific parts of the model, enabling efficient fine-tuning by adapting only a subset of the model parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"attn.c_attn\", \"attn.c_proj\"]  # Target attention layers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training arguments\n",
    "\n",
    "Define the training arguments by using the `TrainingArguments` class from the `transformers` library. These arguments configure various aspects of the training process:\n",
    "\n",
    "- **per_device_train_batch_size=3**: Sets the batch size per device (GPU/CPU) to 3\n",
    "- **num_train_epochs=3**: Specifies the number of training epochs and is set to 3.\n",
    "- **gradient_accumulation_steps=8**: Accumulates gradients over 8 steps before performing a backward/update pass, effectively increasing the batch size\n",
    "- **learning_rate=1.41e-5**: Sets the learning rate for the optimizer to 1.41e-5\n",
    "- **output_dir=\"./model_output3\"**: Specifies the directory where the model checkpoints and other outputs are saved\n",
    "- **logging_steps=10**: Logs training progress every 10 steps\n",
    "- **evaluation_strategy=\"steps\"**: Sets the evaluation strategy to evaluate the model at regular steps\n",
    "- **eval_steps=500**: Evaluates the model every 500 steps\n",
    "- **save_steps=500**: Saves the model checkpoint every 500 steps\n",
    "- **save_total_limit=2**: Limits the number of saved checkpoints to 2, deleting older checkpoints to save space\n",
    "\n",
    "These arguments configure the training loop, including batch size, learning rate, logging, evaluation, and checkpoint-saving strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=3,  # Set to 3\n",
    "    num_train_epochs=3,  # Set to 3\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1.41e-5,\n",
    "    output_dir=\"./model_output3\",\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RewardTrainer\n",
    "\n",
    "The `RewardTrainer` is a specialized trainer that is designed to train models with a reward signal. This is often used in reinforcement learning scenarios where the model learns to optimize for better responses. It is initialized with several parameters:\n",
    "\n",
    "- **model**: The model to be trained\n",
    "- **args**: The training arguments. Typically, an instance of `TrainingArguments`\n",
    "- **tokenizer**: The tokenizer used to process the text inputs\n",
    "- **train_dataset**: The training data set\n",
    "- **eval_dataset**: The evaluation data set\n",
    "- **peft_config**: The configuration for LoRA\n",
    "\n",
    "The `RewardTrainer` orchestrates the training process, handling tasks such as batching, optimization, evaluation, and saving model checkpoints. It is particularly useful for training models that need to learn from feedback signals, improving their ability to generate high-quality responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Initialize RewardTrainer\n",
    "trainer = RewardTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset_dict['train'],\n",
    "    eval_dataset=dataset_dict['test'],\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note: You can safely ignore the above warning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is training, saving, and evaluating a model by using the `RewardTrainer`. The `trainer.train()` method initiates the training process, where the model learns from the training data set, optimizing its parameters to improve performance. After training, the `trainer.save_model(output_dir)` method saves the trained model to the specified output directory, allowing for future use or deployment. Finally, the `trainer.evaluate()` method evaluates the model's performance on the evaluation data set, returning metrics that provide insights into how well the model performs. These metrics are then printed to give a detailed view of the model's evaluation results. \n",
    "\n",
    "Note: The training takes a very long time. Therefore, the model has already been trained and saved for you. If you want to train the model yourself, go ahead and uncomment the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir=\"./model_output3\"\n",
    "\n",
    "# # Train the model\n",
    "# trainer.train()\n",
    "\n",
    "# # Save the model\n",
    "# trainer.save_model(output_dir)\n",
    "\n",
    "# # Evaluate the model\n",
    "# metrics = trainer.evaluate()\n",
    "# print(metrics)\n",
    "\n",
    "# model.config.save_pretrained(\"./backup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, download the pretained model. If you have trained the model yourself, you can skip this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-04 05:59:53--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VZcK8FJ-kQ3nEJoxWGNYTQ/RetriverTrainerModel.zip\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104, 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13238247 (13M) [application/zip]\n",
      "Saving to: ‘RetriverTrainerModel.zip’\n",
      "\n",
      "RetriverTrainerMode 100%[===================>]  12.62M  58.5MB/s    in 0.2s    \n",
      "\n",
      "2024-10-04 05:59:54 (58.5 MB/s) - ‘RetriverTrainerModel.zip’ saved [13238247/13238247]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VZcK8FJ-kQ3nEJoxWGNYTQ/RetriverTrainerModel.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  RetriverTrainerModel.zip\n",
      "   creating: extracted_model/model_output3/\n",
      "  inflating: extracted_model/__MACOSX/._model_output3  \n",
      "   creating: extracted_model/model_output3/checkpoint-2500/\n",
      "  inflating: extracted_model/__MACOSX/model_output3/._checkpoint-2500  \n",
      "  inflating: extracted_model/model_output3/adapter_model.safetensors  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._adapter_model.safetensors  \n",
      "  inflating: extracted_model/model_output3/.DS_Store  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._.DS_Store  \n",
      "  inflating: extracted_model/model_output3/tokenizer_config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._tokenizer_config.json  \n",
      "  inflating: extracted_model/model_output3/special_tokens_map.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._special_tokens_map.json  \n",
      "  inflating: extracted_model/model_output3/config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._config.json  \n",
      "  inflating: extracted_model/model_output3/README.md  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._README.md  \n",
      "  inflating: extracted_model/model_output3/merges.txt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._merges.txt  \n",
      "  inflating: extracted_model/model_output3/training_args.bin  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._training_args.bin  \n",
      "  inflating: extracted_model/model_output3/adapter_config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._adapter_config.json  \n",
      "  inflating: extracted_model/model_output3/vocab.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/._vocab.json  \n",
      "   creating: extracted_model/model_output3/runs/\n",
      "  inflating: extracted_model/__MACOSX/model_output3/._runs  \n",
      "   creating: extracted_model/model_output3/checkpoint-3000/\n",
      "  inflating: extracted_model/__MACOSX/model_output3/._checkpoint-3000  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/adapter_model.safetensors  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._adapter_model.safetensors  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/rng_state.pth  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._rng_state.pth  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/tokenizer_config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._tokenizer_config.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/special_tokens_map.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._special_tokens_map.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/optimizer.pt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._optimizer.pt  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/scheduler.pt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._scheduler.pt  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/README.md  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._README.md  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/merges.txt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._merges.txt  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/training_args.bin  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._training_args.bin  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/adapter_config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._adapter_config.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/vocab.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._vocab.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-2500/trainer_state.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-2500/._trainer_state.json  \n",
      "  inflating: extracted_model/model_output3/runs/.DS_Store  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/runs/._.DS_Store  \n",
      "   creating: extracted_model/model_output3/runs/Jun26_13-15-27_notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps/\n",
      "  inflating: extracted_model/__MACOSX/model_output3/runs/._Jun26_13-15-27_notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/adapter_model.safetensors  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._adapter_model.safetensors  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/rng_state.pth  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._rng_state.pth  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/tokenizer_config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._tokenizer_config.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/special_tokens_map.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._special_tokens_map.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/optimizer.pt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._optimizer.pt  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/scheduler.pt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._scheduler.pt  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/README.md  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._README.md  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/merges.txt  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._merges.txt  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/training_args.bin  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._training_args.bin  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/adapter_config.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._adapter_config.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/vocab.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._vocab.json  \n",
      "  inflating: extracted_model/model_output3/checkpoint-3000/trainer_state.json  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/checkpoint-3000/._trainer_state.json  \n",
      "  inflating: extracted_model/model_output3/runs/Jun26_13-15-27_notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps/events.out.tfevents.1719421727.notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps.131.1  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/runs/Jun26_13-15-27_notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps/._events.out.tfevents.1719421727.notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps.131.1  \n",
      "  inflating: extracted_model/model_output3/runs/Jun26_13-15-27_notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps/events.out.tfevents.1719407764.notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps.131.0  \n",
      "  inflating: extracted_model/__MACOSX/model_output3/runs/Jun26_13-15-27_notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps/._events.out.tfevents.1719407764.notebook-rt231gpu11fae5ea1dd8b4b8086a1ff2f1537614b-7f7c7d6t6vps.131.0  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o RetriverTrainerModel.zip -d extracted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): lora.Linear(\n",
       "            (base_layer): Conv1D(nf=2304, nx=768)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (c_proj): lora.Linear(\n",
       "            (base_layer): Conv1D(nf=768, nx=768)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): ModulesToSaveWrapper(\n",
       "    (original_module): Linear(in_features=768, out_features=1, bias=False)\n",
       "    (modules_to_save): ModuleDict(\n",
       "      (default): Linear(in_features=768, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"./extracted_model/model_output3\", num_labels=1).to(DEVICE)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note: You can safely ignore the above warning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, plot the loss. You can see it converges nicely.\n",
    "\n",
    "Run the below code to unzip the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_file = f\"extracted_model/model_output3/checkpoint-2500/trainer_state.json\"\n",
    "\n",
    "# Read the log file\n",
    "with open(log_file, 'r') as f:\n",
    "    logs = json.load(f)\n",
    "\n",
    "# Extract training loss values\n",
    "steps = []\n",
    "losses = []\n",
    "for log in logs[\"log_history\"]:\n",
    "    if \"loss\" in log:\n",
    "        steps.append(log[\"step\"])\n",
    "        losses.append(log[\"loss\"])\n",
    "\n",
    "# Plot the training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, losses, label=\"Training Loss\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluating the model\n",
    "The `RewardTrainer` uses pairwise comparison to measure the model's ability to distinguish between high and low-quality responses. In pairwise comparison, the model is presented with two responses: one chosen as the preferred response and one as the less preferred (rejected) response. The model evaluates each response in the pair and assigns a score or reward based on its learned criteria. To perform an evaluation, two separate responses are inputted, and the model generates a score that is logit for each response. The response with the higher score is selected as the preferred one, demonstrating the model's capability to accurately prioritize better responses.\n",
    "\n",
    "First, load the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_=GPT2ForSequenceClassification.from_pretrained(\"./extracted_model/model_output3\", num_labels=1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the device (CPU or GPU) for training. You'll check if a GPU is available for use; otherwise, use CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code first tokenizes `text1` by using the tokenizer, converting it into the format required by the model. The `tokenizer` function processes the input text into tensors with padding and truncation to ensure uniform input length, up to a maximum of 512 tokens. The `inputs` are then moved to the GPU, if available, for faster computation. The `model` is also transferred to the GPU. The inputs dictionary is updated to move all of its items to the device (GPU or CPU).\n",
    "\n",
    "The model is then used to generate outputs without computing gradients (`torch.no_grad()`), making the inference process faster and more memory-efficient. The score, the logits from the model's output, are extracted, representing the raw predictions. These logits are then passed through a sigmoid function to convert them into probabilities, which can be interpreted as the model's confidence in the projections. The resulting probabilities are printed or returned for further use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: Sure! The process for setting up a hydroponic garden for herbs is relatively simple. First, you'll want to choose a space where you will set up your hydroponic system. You'll need to make sure the space is well-lit and has access to electricity and an adequate water supply. Next, you'll need to choose the type of hydroponic system you want to use. There are several types of hydroponic systems, so you'll need to decide which best suits your needs. Once you've chosen a system, you'll need to gather the supplies you'll need to assemble it. This includes things like pumps, growing trays, grow lights, and nutrients. Once you've assembled the system, you'll need to add your choice of herbs to the system. Lastly, you'll need to monitor and adjust the system as needed to ensure your herbs are getting the correct amount of light, water, and nutrients.\n"
     ]
    }
   ],
   "source": [
    "text1=train_str['chosen'][0]\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : tensor([[7.8768]])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text1, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Move inputs to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "logit_1 = outputs.logits\n",
    "print(\"Score :\",logit_1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the rejected sample \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: How do I store a bagels for eating at a later date?\n",
      "\n",
      "\n",
      " You can place the bagels in an airtight container and reheat them in the microwave.  Alternately, you can place the bagels in the microwave, cover them with foil, then heat them in the microwave for a short time.\n"
     ]
    }
   ],
   "source": [
    "text2=train_str['rejected'][0]\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : tensor([[-7.8610]])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text2, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Move inputs to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "logit_2 = outputs.logits\n",
    "print(\"Score :\",logit_2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate how pairwise comparison is useful for evaluating and ranking responses based on the model's predictions, use the following code that performs a pairwise comparison. To determine which of the two responses, represented by `logit_1` and `logit_2`, is preferred, compare the logits, which are raw scores output by the model that indicate the quality of the responses. If `logit_1` is greater than `logit_2`, the first response (`text1`) is selected as the better response, and the second response (`text2`) is rejected, printing both the selected and rejected responses along with their respective scores. Conversely, if `logit_2` is greater or equal, the second response (`text2`) is selected, and the first response (`text1`) is rejected, again printing both responses and their scores. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------selected---------\n",
      "\n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: Sure! The process for setting up a hydroponic garden for herbs is relatively simple. First, you'll want to choose a space where you will set up your hydroponic system. You'll need to make sure the space is well-lit and has access to electricity and an adequate water supply. Next, you'll need to choose the type of hydroponic system you want to use. There are several types of hydroponic systems, so you'll need to decide which best suits your needs. Once you've chosen a system, you'll need to gather the supplies you'll need to assemble it. This includes things like pumps, growing trays, grow lights, and nutrients. Once you've assembled the system, you'll need to add your choice of herbs to the system. Lastly, you'll need to monitor and adjust the system as needed to ensure your herbs are getting the correct amount of light, water, and nutrients. 7.876837253570557\n",
      "--------rejected---------\n",
      "\n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: How do I store a bagels for eating at a later date?\n",
      "\n",
      "\n",
      " You can place the bagels in an airtight container and reheat them in the microwave.  Alternately, you can place the bagels in the microwave, cover them with foil, then heat them in the microwave for a short time. -7.860965251922607\n"
     ]
    }
   ],
   "source": [
    "if logit_1 > logit_2:\n",
    "    print(\"--------selected---------\")\n",
    "    print(text1, logit_1.detach().item())\n",
    "    print(\"--------rejected---------\")\n",
    "    print(text2, logit_2.detach().item())\n",
    "else:\n",
    "    print(\"selected \")\n",
    "    print(text2, logit_2.detach().item())\n",
    "    print(\"rejected\")\n",
    "    print(text2, logit_2.detach().item())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, convert the process of tokenizing, generating a score, and comparing the outputs into two separate functions. The first function handles tokenizing the text and generating the model's output scores, while the second function performs the pairwise comparison of these scores. Structuring the code this way ensures that the process is modular and easier to manage, facilitating a clear and efficient workflow for evaluating and selecting the better response based on the model's predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a prediction and get the logits\n",
    "def predict_and_get_logits(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Perform the forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model_(**inputs)\n",
    "    \n",
    "    # Extract the logits from the outputs\n",
    "    logits = outputs.logits.squeeze().item()  # Assuming binary classification and batch size of 1\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare two texts\n",
    "def compare_texts(text1, text2):\n",
    "    logit1 = predict_and_get_logits(text1)\n",
    "    logit2 = predict_and_get_logits(text2)\n",
    "\n",
    "    if logit1 > logit2:\n",
    "        print(\"selected---------\")\n",
    "        print(text1, f\"score: {logit1}\")\n",
    "\n",
    "        return text1\n",
    "    else:\n",
    "        print(\"selected---------\")\n",
    "        print(text2,  f\"score: {logit2}\")\n",
    "\n",
    "        return text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally,  evaluate the performance of a model by using a pairwise comparison approach over a subset of the data set. It begins by defining N, the number of samples to evaluate, and initializes a counter `correct_selections` to keep track of how many times the model correctly identifies the preferred response. The code then iterates over the first N pairs of chosen and rejected responses from the training data set (`train_str['chosen']` and `train_str['rejected']`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: Sure! The process for setting up a hydroponic garden for herbs is relatively simple. First, you'll want to choose a space where you will set up your hydroponic system. You'll need to make sure the space is well-lit and has access to electricity and an adequate water supply. Next, you'll need to choose the type of hydroponic system you want to use. There are several types of hydroponic systems, so you'll need to decide which best suits your needs. Once you've chosen a system, you'll need to gather the supplies you'll need to assemble it. This includes things like pumps, growing trays, grow lights, and nutrients. Once you've assembled the system, you'll need to add your choice of herbs to the system. Lastly, you'll need to monitor and adjust the system as needed to ensure your herbs are getting the correct amount of light, water, and nutrients.\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: I was wondering if you could walk me through the process of setting up a hydroponic garden for herbs.\n",
      "\n",
      "Assistant: Sure! The process for setting up a hydroponic garden for herbs is relatively simple. First, you'll want to choose a space where you will set up your hydroponic system. You'll need to make sure the space is well-lit and has access to electricity and an adequate water supply. Next, you'll need to choose the type of hydroponic system you want to use. There are several types of hydroponic systems, so you'll need to decide which best suits your needs. Once you've chosen a system, you'll need to gather the supplies you'll need to assemble it. This includes things like pumps, growing trays, grow lights, and nutrients. Once you've assembled the system, you'll need to add your choice of herbs to the system. Lastly, you'll need to monitor and adjust the system as needed to ensure your herbs are getting the correct amount of light, water, and nutrients. score: 7.631243705749512\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: What type of wine goes best with steak.\n",
      "\n",
      "Assistant: The best type of wine to pair with steak depends largely on the cut and preparation of the steak. Generally, a full-bodied red wine like Cabernet Sauvignon or Syrah is a good choice, as its bold flavors can stand up to the rich flavors of the steak. Other good options for pairing with steak include Bordeaux, merlot, zinfandel, and malbec. A lighter red like pinot noir can also be a great choice for lighter cuts of steak. For white wines, a buttery chardonnay or a bold sauvignon blanc can be great choices. A sparkling wine, such as Prosecco, can also go well with steak.\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What type of wine goes best with steak.\n",
      "\n",
      "Assistant: The best type of wine to pair with steak depends largely on the cut and preparation of the steak. Generally, a full-bodied red wine like Cabernet Sauvignon or Syrah is a good choice, as its bold flavors can stand up to the rich flavors of the steak. Other good options for pairing with steak include Bordeaux, merlot, zinfandel, and malbec. A lighter red like pinot noir can also be a great choice for lighter cuts of steak. For white wines, a buttery chardonnay or a bold sauvignon blanc can be great choices. A sparkling wine, such as Prosecco, can also go well with steak. score: 9.034623146057129\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: How do I know if this is a good investment.\n",
      "\n",
      "Assistant: Answer: To determine if an investment is a good one, it is important to consider the potential risks and rewards of the investment, as well as the cost, expected rate of return, and timeline involved in the investment. Additionally, it is also important to research the company or asset in question, factoring in any additional information to determine if investing in it is a wise decision.\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How do I know if this is a good investment.\n",
      "\n",
      "Assistant: Answer: To determine if an investment is a good one, it is important to consider the potential risks and rewards of the investment, as well as the cost, expected rate of return, and timeline involved in the investment. Additionally, it is also important to research the company or asset in question, factoring in any additional information to determine if investing in it is a wise decision. score: 8.213390350341797\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: Please provide me with some financial advice.\n",
      "\n",
      "Assistant: Some financial advice is to always pay yourself first. Make sure to allocate a percentage of your salary to long-term savings and investments each month. Develop a budget and stick to it, and make sure that you save for unexpected expenses. Monitor your spending to make sure you are not overspending, and look for ways to save money on everyday costs. Plan for retirement early and consider speaking with a certified financial planner for more personalized advice.\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: Please provide me with some financial advice.\n",
      "\n",
      "Assistant: Some financial advice is to always pay yourself first. Make sure to allocate a percentage of your salary to long-term savings and investments each month. Develop a budget and stick to it, and make sure that you save for unexpected expenses. Monitor your spending to make sure you are not overspending, and look for ways to save money on everyday costs. Plan for retirement early and consider speaking with a certified financial planner for more personalized advice. score: 9.226421356201172\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: What kind of safety devices do I need to install in my house.\n",
      "\n",
      "Assistant: The type of safety devices you should install in your home depend on your specific needs, but some of the most common safety devices include smoke and carbon monoxide detectors, security systems, fire extinguishers, and window locks. Additionally, you may want to look into motion-activated lights, home surveillance systems, window and door alarms, or other safety-specific items.\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What kind of safety devices do I need to install in my house.\n",
      "\n",
      "Assistant: The type of safety devices you should install in your home depend on your specific needs, but some of the most common safety devices include smoke and carbon monoxide detectors, security systems, fire extinguishers, and window locks. Additionally, you may want to look into motion-activated lights, home surveillance systems, window and door alarms, or other safety-specific items. score: 8.424080848693848\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: How do I interpret the results of my blood test.\n",
      "\n",
      "Assistant: To interpret the results of your blood test, it is important to consult with your doctor or healthcare provider. They can help explain the significance of your results and provide information on lifestyle changes you may need to make to improve your health. Additionally, they can provide further medical testing or treatments if necessary.\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How do I interpret the results of my blood test.\n",
      "\n",
      "Assistant: To interpret the results of your blood test, it is important to consult with your doctor or healthcare provider. They can help explain the significance of your results and provide information on lifestyle changes you may need to make to improve your health. Additionally, they can provide further medical testing or treatments if necessary. score: 8.769942283630371\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: I'm having trouble finding the perfect job. What resources can help me.\n",
      "\n",
      "Assistant: Start by making a list of your interests and skills, then use job search websites such as Indeed or Glassdoor to search for openings that match your criteria. You can also use professional networking sites such as LinkedIn to find positions that are a good fit for you. Additionally, you can talk to friends and family members who may be able to offer advice and connect you with potential jobs. Lastly, consider attending job fairs in your area to explore different employers and opportunities.\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: I'm having trouble finding the perfect job. What resources can help me.\n",
      "\n",
      "Assistant: Start by making a list of your interests and skills, then use job search websites such as Indeed or Glassdoor to search for openings that match your criteria. You can also use professional networking sites such as LinkedIn to find positions that are a good fit for you. Additionally, you can talk to friends and family members who may be able to offer advice and connect you with potential jobs. Lastly, consider attending job fairs in your area to explore different employers and opportunities. score: 10.092340469360352\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: What does a roux look like.\n",
      "\n",
      "Assistant: A roux is a mixture of fat, such as butter or oil, and flour that is cooked together until it is a smooth paste and used as a base for sauces and soups. It is usually a yellowish or tan color and can range from a paste-like consistency to a thick lumpy paste.\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What does a roux look like.\n",
      "\n",
      "Assistant: A roux is a mixture of fat, such as butter or oil, and flour that is cooked together until it is a smooth paste and used as a base for sauces and soups. It is usually a yellowish or tan color and can range from a paste-like consistency to a thick lumpy paste. score: 3.8545234203338623\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: How to make money online.\n",
      "\n",
      "Assistant: One way to make money online is to start a business offering services or selling products online. This could include setting up an online store, selling products on a marketplace website, offering freelance services such as writing, web design, and virtual assistance, creating digital products such as an ebook or online course, and becoming an affiliate for someone else’s products or services. Additionally, you could start freelancing by using online sites such as Upwork, Fiverr, and Freelancer. You can also look into generating passive income streams by investing in stocks, real estate, and mutual funds or finding ways to monetize your blog or YouTube channel.\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How to make money online.\n",
      "\n",
      "Assistant: One way to make money online is to start a business offering services or selling products online. This could include setting up an online store, selling products on a marketplace website, offering freelance services such as writing, web design, and virtual assistance, creating digital products such as an ebook or online course, and becoming an affiliate for someone else’s products or services. Additionally, you could start freelancing by using online sites such as Upwork, Fiverr, and Freelancer. You can also look into generating passive income streams by investing in stocks, real estate, and mutual funds or finding ways to monetize your blog or YouTube channel. score: 6.15497350692749\n",
      "Chosen Response:\n",
      " \n",
      "\n",
      "Human: What are some job options for engineering majors.\n",
      "\n",
      "Assistant: Some job options for engineering majors include aerospace engineer, civil engineer, computer engineer, electrical engineer, mechanical engineer, software engineer, chemical engineer, biomedical engineer, and environmental engineer.\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What are some job options for engineering majors.\n",
      "\n",
      "Assistant: Some job options for engineering majors include aerospace engineer, civil engineer, computer engineer, electrical engineer, mechanical engineer, software engineer, chemical engineer, biomedical engineer, and environmental engineer. score: 4.520879745483398\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Define the number of samples to evaluate\n",
    "N = 10\n",
    "\n",
    "# Initialize a counter for correct selections\n",
    "correct_selections = 0\n",
    "\n",
    "# Iterate over the first N pairs of chosen and rejected responses\n",
    "for chosen, rejected in zip(train_str['chosen'][0:N], train_str['rejected'][0:N]):\n",
    "    # Print the chosen response for reference\n",
    "    print(\"Chosen Response:\\n\", chosen)\n",
    "    \n",
    "    # Use the compare_texts function to determine which response is better\n",
    "    selected_text = compare_texts(chosen, rejected)\n",
    "    \n",
    "    # Check if the selected text is the chosen response\n",
    "    if selected_text == chosen:\n",
    "        correct_selections += 1\n",
    "\n",
    "# Calculate the accuracy as the ratio of correct selections to the total number of samples\n",
    "accuracy = correct_selections / N\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "#### Evaluate model's preference accuracy on a different subset of data\n",
    "\n",
    "1. Define a new variable `K` to set the number of samples for evaluation from a different subset of the data.\n",
    "2. Initialize a counter to track the number of correct selections made by the model.\n",
    "3. Iterate over the `K` pairs of chosen and rejected responses from a different subset of the data set (for example, from the middle of the data set).\n",
    "4. For each pair, use the `compare_texts` function to determine which response is better.\n",
    "5. Count the number of times the model correctly identifies the chosen response.\n",
    "6. Calculate and print the accuracy of the model's preferences on this different subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected---------\n",
      "\n",
      "\n",
      "Human: What's the best way to store old wines.\n",
      "\n",
      "Assistant: The best way to store old wines is in a cool, dark place, away from direct sunlight and with temperatures that stay consistent. It is important to also ensure that the humidity levels are reasonably high, as this helps keep the cork moist. Finally, wine should always be stored on its side to keep the cork wet and prevent air from entering the bottle. score: 7.480734825134277\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What kids activities can I do that link to geography.\n",
      "\n",
      "Assistant: One activity you can do with kids that link to geography is to make a map. Have them draw a map of their local area or even the world. They can use a variety of resources like books, online maps, and even globe ornaments. Talk about the features: rivers, mountains, cities, parks, and more. Give them a homework assignment to learn about some geographic area and then ask them to teach the class about that location. You can also bring in a variety of items to show the different geographic areas, such as a bag of rocks, a map of the world, coins from different countries, etc. Additionally, you can ask the kids to make a travel diary as if they had just visited a place. They can document their experience throughout their imagined journey – what people and landmarks they visited, what foods were tasted, and what photos were taken – all within the context of geography. score: 1.9571967124938965\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How can I reheat food safely.\n",
      "\n",
      "Assistant: To reheat food safely, place the food in an oven-safe container and heat in the oven at 350°F for about 20 minutes. Alternatively, you can microwave the food in 30-second increments, stirring between each interval to ensure even heating. If reheating in a microwave, use a microwave-safe dish and cover the food to prevent splatter. Be sure to check the temperature of the reheated food before consuming. score: 8.292635917663574\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What are some tips for creative writing.\n",
      "\n",
      "Assistant: Brainstorm ideas and explore different writing styles.\n",
      "2. Read often to stay inspired and observe different techniques.\n",
      "3. Start by writing about what you know and explore new topics.\n",
      "4. Make an outline to plan the structure of your story.\n",
      "5. Keep a writing journal to capture ideas and let your imagination flow.\n",
      "6. Write with your emotions and stay authentic to your voice.\n",
      "7. Develop realistic and dynamic characters with unique traits.\n",
      "8. Allow yourself to take risks and accept constructive criticism.\n",
      "9. Take regular breaks to create perspective and focus.\n",
      "10. Embrace imperfection and have fun exploring the craft of writing. score: 7.629550457000732\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: I need advice on how to start my own business.\n",
      "\n",
      "Assistant: Start by making a business plan. Outline your goals and sketch out a road map of how you will achieve them. Research the industry you’re entering and the competition, and be sure to price your products and services competitively. Also look into the legal steps needed to get your business off the ground. Create a list of potential customers and develop marketing strategies to reach them. Finally, make sure you have enough capital to cover your business in its early stages. Taking the time to plan and prepare will put you on the right path to success. score: 7.3404316902160645\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: I'd like some tips for saving money on groceries.\n",
      "\n",
      "Assistant: Plan your meals ahead of time and create a grocery list to buy only what you need. \n",
      "2. Compare prices between different stores and brands.\n",
      "3. Buy items in bulk when it makes sense.\n",
      "4. Take advantage of coupons, rewards programs, and special promotions. \n",
      "5. Stock up on staples when they go on sale. \n",
      "6. Use a cashback app when shopping to get money back. \n",
      "7. Buy generic items instead of name brand items. \n",
      "8. Look for store discounts for buying multiple items. \n",
      "9. Buy fresh produce in season for the freshest and cheapest options.\n",
      "10. Buy store brand items whenever possible. score: 5.449475288391113\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How can I make a holiday dinner on a budget.\n",
      "\n",
      "Assistant: One way to make a holiday dinner on a budget is to use items you already have in your kitchen. You can make a delicious dinner without spending a lot of money by getting creative with staples like rice, pasta, grains, and/or beans. Consider using cheaper cuts of meat or opting for vegetarian alternatives. Look for sales and discounts at your local grocery store or farmers' market, where you can purchase in-season fruits and vegetables at a lower price than other times of year. You can also use frozen and canned foods like soups, sauces, and vegetables to stretch your budget. Finally, check out websites like Budgetbytes.com, which gives step-by-step recipes that can help you create a delicious and budget-friendly holiday dinner. score: 10.170543670654297\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: I'm looking to sell some of my old clothes online. What tips can you offer me.\n",
      "\n",
      "Assistant: Take clear photographs of your clothes from various angles and make sure the lighting is good. \n",
      "2. Provide as much detail as possible in the description to set your clothes apart from the competition.\n",
      "3. Research current fashion trends and label accordingly.\n",
      "4. Be honest about the condition of the clothes so buyers will not be disappointed.\n",
      "5. Use online marketplaces like eBay and Etsy that are designed for selling clothes.\n",
      "6. Consider offering free shipping to attract customers.\n",
      "7. Charge a reasonable price that reflects the value and condition of your clothes. score: 5.703405857086182\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How do I make sure a job interview goes smoothly.\n",
      "\n",
      "Assistant: To make sure a job interview goes smoothly, it's important to be prepared and confident. Make sure you have done your research about the company and the job position, have questions ready to ask the interviewer, dress professionally, and come with a positive attitude. Additionally, be sure to arrive to the interview on time and be polite and courteous to all the people you meet. Lastly, focus on the skills you can bring to the job and provide concrete examples of what you can do. score: 9.323196411132812\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: My friend is a home chef and he's looking for different recipes to try out. What can you suggest.\n",
      "\n",
      "Assistant: Thai Green Curry \n",
      "2  Chicken Tikka Masala \n",
      "3  Grilled Salmon with Lemon-Caper Sauce \n",
      "4  French Onion Soup \n",
      "5  Jalapeno Popper Pizza \n",
      "6  Pesto Lasagna \n",
      "7  Greek Salad with Feta \n",
      "8  Mexican Skillet Casserole \n",
      "9  Broccoli Macaroni and Cheese \n",
      "10  Stuffed Peppers with Rice and Cheese. score: 1.3256522417068481\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: I recently started a blog and I'm trying to figure out how to make it more successful. What are some strategies I can use.\n",
      "\n",
      "Assistant: Some strategies to make your blog more successful include: \n",
      "1. Implement SEO strategies, such as using keywords and backlinks.\n",
      "2. Offer content that is unique, engaging, and relevant to your intended audience.\n",
      "3. Consider guest blogging to build a higher profile.\n",
      "4. Engage with readers by responding to comments and questions.\n",
      "5. Regularly post content to keep readers interested and coming back.\n",
      "6. Analyze what’s working and what isn’t, then adjust accordingly. \n",
      "7. Create content in multiple formats, such as videos, articles, and graphics.\n",
      "8. Take advantage of social media by promoting your blog and connecting with followers.\n",
      "9. Make sure to have a visually appealing design, both on your blog and in other media.\n",
      "10. Utilize email marketing to keep your readers informed. score: 7.292527675628662\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What are some ways to make my home smarter.\n",
      "\n",
      "Assistant: Some ways to make your home smarter include installing a smart home security system, adding voice-activated technology such as Google Home or Amazon Alexa, programming smart thermostats, dimmers and lighting controls, setting up automated appliances, adding video doorbells and smart locks, and integrating a smart home hub. score: 7.677630424499512\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What are some good exercises for a beginner yoga class.\n",
      "\n",
      "Assistant: Some good exercises for a beginner yoga class include Child's Pose, Cat-Cow Pose, Downward Facing Dog, Forward Fold, Upward Facing Dog, Warrior 1, and Tree Pose. score: 4.352787494659424\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What type of meditation should I do for calming my mind.\n",
      "\n",
      "Assistant: It depends on what you are looking for. If you are seeking relaxation, guided meditation or mindfulness meditation might be a good option. If you are looking to improve your focus and concentration, mantra meditation or Transcendental Meditation could be a good choice. Other types of meditation such as yoga, qigong, and tai chi may also be helpful in calming the mind. Experiment with different approaches and find what works best for you. score: 9.48099422454834\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What is the best type of paint to use for a kitchen wall.\n",
      "\n",
      "Assistant: The best type of paint to use for a kitchen wall is a washable, eggshell, or satin finish. It is best to use a paint that is easy to clean and is resistant to stains and moisture. score: 4.718678951263428\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What should I consider before signing up for a gym.\n",
      "\n",
      "Assistant: Before signing up for a gym, you should consider: \n",
      "1. The amenities and equipment that the gym offers.\n",
      "2. The cost for a membership and any additional fees.\n",
      "3. The hours of operation and the availability of classes.\n",
      "4. Whether the gym offers a trial membership or day fees.\n",
      "5. The proximity of the gym to your home or workplace.\n",
      "6. Any online reviews or ratings from previous members.\n",
      "7. Whether the gym has a professional staff available to answer questions or provide support.\n",
      "8. The availability of showers, lockers, and other amenities.\n",
      "9. Whether the gym membership includes access to other locations.\n",
      "10. The cleanliness of the facilities and any existing customer feedback. score: 7.464560031890869\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What's the best way to remember complex formulas quickly.\n",
      "\n",
      "Assistant: The best way to remember complex formulas quickly is to practice them often and break them down into smaller parts that are easy to remember and visualize. Additionally, creating mnemonics or acronyms can help to quickly recall the formulas. Finally, associating formulas with real world examples can make them easier to remember. score: 9.4314546585083\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What are the benefits of having a fitness routine.\n",
      "\n",
      "Assistant: The benefits of having a fitness routine include increased energy levels, improved mood, weight loss, increased strength and endurance, improved cardiovascular health, and reduced risk of chronic diseases. Additionally, having a fitness routine can help to promote better sleep and reduce stress. score: 8.812758445739746\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What are the environmental impacts of buying fast fashion.\n",
      "\n",
      "Assistant: The environmental impacts of buying fast fashion are wide-ranging and extensive. Fast fashion production typically uses synthetic materials that require a great deal of energy to produce and generate significant amounts of greenhouse gases and other pollutants. Additionally, fast fashion production uses large amounts of water, often resulting in water pollution and scarcity in the surrounding area. After being produced, fast fashion garments often travel long distances and generate a lot of waste as they are made, packaged and distributed. Finally, due to their often poor quality, fast fashion garments have a short lifespan and are rarely recycled or reused, creating an immense amount of textile waste, with serious environmental implications. score: 7.803715705871582\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: Is drinking green tea good for my health.\n",
      "\n",
      "Assistant: Yes, drinking green tea is good for your health. It contains antioxidants, which can help boost your immunity, improve metabolism, and reduce the risk of certain types of cancer. Green tea also contains beneficial compounds like epigallocatechin gallate (EGCG) that can help protect your heart, reduce inflammation, and improve mental alertness. score: 7.586577892303467\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What are the tax implications of investing in real estate.\n",
      "\n",
      "Assistant: The tax implications of investing in real estate vary depending on the type of property you purchase and the form of ownership you choose. Generally, gains from the sale of real estate are subject to capital gains taxes in most countries, while income from renting out real estate may be subject to income tax. Additionally, you may be required to pay property tax and other local taxes, depending on the region or municipality. It is advisable to seek professional advice concerning any tax implications associated with investing in real estate. score: 9.352088928222656\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What are the main types of financial instruments.\n",
      "\n",
      "Assistant: The main types of financial instruments include stocks, bonds, derivatives, mutual funds, commodities, currencies, and insurance products. score: 5.112833023071289\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What is the most popular podcast right now.\n",
      "\n",
      "Assistant: The most popular podcast right now is The Joe Rogan Experience. score: -4.260443687438965\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What is the most advanced artificial intelligence right now.\n",
      "\n",
      "Assistant: The most advanced artificial intelligence right now is most likely deep learning technology. Deep learning utilizes neural networks to learn complex patterns in large amounts of data, enabling machines to make decisions that are analogous to those made by humans. score: 2.080514669418335\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What are the common symptoms of a cold.\n",
      "\n",
      "Assistant: Common symptoms of a cold include a sore throat, runny nose, coughing, sneezing, fatigue, body aches and a fever. score: 3.714022636413574\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How to I go about organizing a small event for my friends in the current world climate.\n",
      "\n",
      "Assistant: In the current world climate, it is important to consider the health and safety of both yourself and your friends before planning an event. The best practice for organizing a small event would be to adhere to the local health guidelines and social distancing practices that are recommended in your area. You could consider an outdoor event where physical distancing is possible, such as a picnic or a barbecue. If you decide to have an indoor event, you may want to limit the number of people attending, encourage everyone to wear masks, and keep the gathering short. Additionally, you could provide hand sanitizer and hygiene items to ensure the safety of your guests. score: 8.427621841430664\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How can I make myself a better person.\n",
      "\n",
      "Assistant: One way to make yourself a better person is to set achievable goals for yourself and work towards them each day. Focus on improving yourself in areas such as self-discipline, communication, and problem-solving skills. Additionally, strive to be kind and understanding of others, as well as being honest and loyal in all interactions. Finally, take some time to reflect and appreciate the progress you have made, and remember to strive for personal growth no matter how small or insignificant it may seem at first. score: 9.603994369506836\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What is the best practice to follow when interviewing for a job.\n",
      "\n",
      "Assistant: The best practice to follow when interviewing for a job is to be prepared and be yourself. Research the company extensively to understand the job requirements, mission, and culture. Be organized and come prepared with multiple copies of your resume and examples of your accomplishments. Additionally, be communicative and express enthusiasm. Be confident but not overly assertive, and be sure to follow up after the meeting. score: 10.223722457885742\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How do I research a new hobby I'm interested in.\n",
      "\n",
      "Assistant: Start by doing a basic online search for the hobby that you are interested in. Look for websites and resources that provide information about the hobby. \n",
      "\n",
      "2  Read descriptions of the hobby and find out what skills and materials you need in order to participate in it. \n",
      "\n",
      "3  Reach out to people who already practice the hobby and ask them questions about it. Check out hobby-related forums or discussion boards where people can share tips and advice.\n",
      "\n",
      "4  Watch videos and tutorials about the hobby. Join online communities dedicated to it and learn from experienced hobbyists. \n",
      "\n",
      "5  Research your local area for available classes or join a club or organization related to the hobby. Visit stores and shops that specialize in the hobby to get supplies and equipment. \n",
      "\n",
      "6  Experiment and explore different ways of practicing the hobby. Try to find resources that will help you track your progress and reach your goals. score: 9.891705513000488\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How can I find a therapist that I can trust and is well suited to my needs.\n",
      "\n",
      "Assistant: One way to find a therapist that you can trust and is well suited to your needs is to do your research. Look for reviews online, ask friends and family for recommendations, and contact local therapists to ask questions and see if they would be a good fit. You can also consider asking your doctor or primary care provider for referrals, as they may have a better understanding of your needs and be able to suggest an appropriate therapist for you. score: 9.354408264160156\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What is the best way to get rid of bugs in a houseplant.\n",
      "\n",
      "Assistant: The best way to get rid of bugs in a houseplant is to use a safe and natural insecticide such as neem oil or horticultural oil. Be sure to follow the instructions on the product label to ensure safe and effective use. Additionally, prune off affected branches and leaves and dispose of them away from the plant. For further prevention, ensure the plant is receiving enough light and water and that the soil is aerated to allow for adequate drainage. score: 8.877033233642578\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How can I organize my desk space optimally.\n",
      "\n",
      "Assistant: One way to organize your desk space optimally is to divide up the space into zones for different activities, such as a space for writing and a space for computing. You can also use storage containers, shelves, and drawers to organize and store items, as well as use desk organizers to keep paperwork or other items arranged in an orderly fashion. You should also consider the desk layout and positioning of the items on your desk to make the most efficient use of your space. score: 9.471436500549316\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How can I improve my public speaking skills.\n",
      "\n",
      "Assistant: One way to improve your public speaking skills is to practice as often as possible. Start by giving presentations in front of friends or family and gradually build up your confidence by presenting in front of larger groups. Practice making eye contact with your audience and speaking clearly and loudly. You may also want to research and become familiar with the topic you are going to speak about. Finally, take some time to visualize yourself talking confidently and successfully during the presentation. score: 9.508315086364746\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What is the latest updates on developments in artificial intelligence.\n",
      "\n",
      "Assistant: According to recent reports, advancements in artificial intelligence are rapidly being made. Researchers have developed new techniques for enabling machines to analyze large amounts of data, as well as to become more intelligent in tasks such as natural language processing, image recognition, and self-driving cars. Additionally, new AI technologies are being used to solve complex problems such as helping reduce energy consumption and improving healthcare delivery. It is evident that AI is revolutionizing the way businesses and people interact with the world. score: 6.753899574279785\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What is a low-cost way to travel Europe.\n",
      "\n",
      "Assistant: A great way to travel Europe on a budget is to take advantage of budget airlines like Ryanair, EasyJet, and WizzAir, which offer affordable flights between many cities throughout Europe. Additionally, using public transportation such as trains and buses can help you save money while exploring the continent. Staying in hostels and taking free walking tours can also be great cost-saving options. score: 10.316863059997559\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What is the insect repellent that is most effective.\n",
      "\n",
      "Assistant: The most effective insect repellent is DEET. It has been proven to be the best at repelling insects for up to 8 hours. score: 0.8876404166221619\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: I'm looking for advice on starting a small business.\n",
      "\n",
      "Assistant: One of the best pieces of advice for starting a small business is to create a business plan. A business plan helps you develop a clear strategy for how you want to grow your business. It also keeps you organized and on track as you start your business. Additionally, a business plan can help you secure financing from investors or lenders. Finally, make sure that you research the market before starting your business and know your competitors. Good luck. score: 9.227239608764648\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What's the best way to back up my computer data.\n",
      "\n",
      "Assistant: The best way to back up your computer data is to use an external hard drive or cloud storage services such as Google Drive or Dropbox. Regular backups should be done to ensure that all of your important files are securely stored. Additionally, it's important to check that your backups are working properly to prevent any data loss. score: 8.790387153625488\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: I'm trying to find a good place to watch a movie.\n",
      "\n",
      "Assistant: A good place to watch a movie is a movie theater. Many theaters offer comfortable seating, state-of-the-art audio and video equipment, as well as concessions like popcorn, candy and beverages. Some theaters also offer rewards programs and special discounts. Alternatively, you could consider opting for a night at home and ordering a movie through a streaming service like Netflix or Hulu. score: 8.845212936401367\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What is the most secure way to store financial information.\n",
      "\n",
      "Assistant: The most secure way to store financial information is to encrypt it using a reliable and secure encryption software, such as AES-256 encryption. Additionally, it is important to store the data in a secure storage system and use strong passwords to protect access. Finally, ensure that backups are made so that the data can be quickly recovered in the event of a breach. score: 8.50065803527832\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How do I apply for a passport in the USA.\n",
      "\n",
      "Assistant: In order to apply for a passport in the United States, you will need to submit a passport application form, proof of citizenship, and a valid form of identification. You can find the necessary forms on the U.S. State Department website and submit them either via mail or in person to a passport office or acceptance facility. Depending on the type of passport you are applying for, you may also need to provide a passport photo. score: 5.121849060058594\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: How do I make an easy 5-ingredient guacamole.\n",
      "\n",
      "Assistant: To make an easy 5-ingredient guacamole, you will need 2 avocados, 1/4 cup diced onion, 1/4 cup diced tomatoes, 1/4 teaspoon garlic powder and 2 tablespoons of lime juice. Begin by mashing the avocados in a bowl, then add all the other diced ingredients, garlic powder and lime juice. Mix all the ingredients together until evenly distributed and serve your homemade guacamole with your favorite chips or veggies. Enjoy. score: 9.099556922912598\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What are some important tips for going on a long road trip.\n",
      "\n",
      "Assistant: Make sure your car is in good working condition before going on a long road trip, doing a full inspection and maintenance check. \n",
      "2. Always plan ahead and make sure you have a good roadmap or navigation system. \n",
      "3. Have plenty of snacks and drinks for your trip. \n",
      "4. Pack an emergency kit with items like a first-aid kit, flashlights, jumper cables, blankets, and lots of water.\n",
      "5. If you are driving a long distance, take frequent breaks to get some rest and move around.\n",
      "6. Make sure your smartphone is fully charged and bring a phone charger, just in case. \n",
      "7. Check the weather in your route and plan accordingly. \n",
      "8. Let someone else know your route and approximate arrival time. score: 4.660353183746338\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: Where are the best places to find vegan friendly restaurants in New York City.\n",
      "\n",
      "Assistant: The best places to find vegan friendly restaurants in New York City are in popular vegan hotspots such as the East Village, Greenwich Village, Williamsburg, and Astoria. Other popular vegan restaurants throughout the city can be found in Harlem, the Lower East Side, Chelsea, and Chinatown. score: 8.150627136230469\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: What are the main components of a computer and how do they work together.\n",
      "\n",
      "Assistant: The main components of a computer are the processor, motherboard, memory, storage, power supply, display, and peripherals. The processor is the central processing unit of the computer, responsible for interpreting and executing instructions. The motherboard serves as a base for these components, providing power and a communication pathway for data transfer. Memory is used to store information that is temporarily used by the processor. Storage holds data and programs more permanently. The power supply converts alternating current from a power outlet to direct current that the computer can use, and the display is the visual output of the computer. The peripherals are the input and output devices, such as the keyboard, mouse, printer, and microphone, which allow the user to interact with the computer. All of these components work together to receive, process, and store information as instructed by the user. score: 8.815923690795898\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: Based on my credit score, what types of credit card and loan offers can I get.\n",
      "\n",
      "Assistant: Depending on your credit score, you may be eligible for various loan and credit card offers, such as low-interest rate credit cards, rewards credit cards, business credit cards, student loans, home loans, car loans, and more. score: 6.812512397766113\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: Does the size of a company and a company's budget determine the type of marketing they should do.\n",
      "\n",
      "Assistant: The size of a company and its budget can certainly be influential in determining the marketing strategies and tactics it should pursue. However, there are other factors to consider, such as the target audience, the company's objectives and goals, and available resources. Ultimately, a company should consider all of these elements to develop an effective marketing plan that meets its unique needs and goals. score: 9.447745323181152\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: I'm planning a big family reunion with relatives from out of town. How can I make sure that no one feels left out.\n",
      "\n",
      "Assistant: One way to make sure no one feels left out is to plan structured activities that everyone can take part in. This could include team-building games, icebreakers, or family-oriented games. Another idea could be to assign each family member a job, such as organizing the food, setting up decorations, or helping with activities. Doing this gives everyone a sense of belonging and purpose, helping them to feel included. You could also provide opportunities to be social, like group meals, or one-on-one conversations to get to know each other better. Finally, take the time to appreciate each family member, and ask open-ended questions that invite conversation. By creating an inviting and inclusive atmosphere, everyone will feel welcome and appreciated. score: 8.650508880615234\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: Is it better for my health to exercise for 20 minutes in the morning or take a break during the day for a 10 minute walk.\n",
      "\n",
      "Assistant: It's hard to say which is better for your health without knowing your specific health goals and lifestyle. However, both activities can be beneficial in different ways. Exercising for 20 minutes in the morning can give you a burst of energy and help set the tone for the rest of your day, while taking a short 10 minute walk during the day can provide a break from work and help you refocus and relax. Ultimately, it comes down to what works best for you and your individual needs. score: 8.621736526489258\n",
      "selected---------\n",
      "\n",
      "\n",
      "Human: Are there any online courses that I can take that would help me become a better leader.\n",
      "\n",
      "Assistant: Yes, there are many online courses that can help you become a better leader. You can find courses on topics such as communication, conflict resolution, team building, decision making, problem solving, goal setting, and more. score: 0.20949897170066833\n",
      "Accuracy on different subset: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "# Define the number of samples to evaluate from a different subset\n",
    "K = 50\n",
    "\n",
    "# Initialize a counter for correct selections\n",
    "correct_selections = 0\n",
    "\n",
    "# Determine the starting index for the different subset (e.g., middle of the dataset)\n",
    "start_index = len(train_str['chosen']) // 2\n",
    "\n",
    "# Iterate over K pairs of chosen and rejected responses from the different subset\n",
    "for chosen, rejected in zip(train_str['chosen'][start_index:start_index + K], train_str['rejected'][start_index:start_index + K]):\n",
    "    # Use the compare_texts function to determine which response is better\n",
    "    selected_text = compare_texts(chosen, rejected)\n",
    "    \n",
    "    # Check if the selected text is the chosen response\n",
    "    if selected_text == chosen:\n",
    "        correct_selections += 1\n",
    "\n",
    "# Calculate the accuracy as the ratio of correct selections to the total number of samples\n",
    "accuracy = correct_selections / K\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy on different subset:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# Define the number of samples to evaluate from a different subset\n",
    "K = 50\n",
    "\n",
    "# Initialize a counter for correct selections\n",
    "correct_selections = 0\n",
    "\n",
    "# Determine the starting index for the different subset (e.g., middle of the dataset)\n",
    "start_index = len(train_str['chosen']) // 2\n",
    "\n",
    "# Iterate over K pairs of chosen and rejected responses from the different subset\n",
    "for chosen, rejected in zip(train_str['chosen'][start_index:start_index + K], train_str['rejected'][start_index:start_index + K]):\n",
    "    # Use the compare_texts function to determine which response is better\n",
    "    selected_text = compare_texts(chosen, rejected)\n",
    "    \n",
    "    # Check if the selected text is the chosen response\n",
    "    if selected_text == chosen:\n",
    "        correct_selections += 1\n",
    "\n",
    "# Calculate the accuracy as the ratio of correct selections to the total number of samples\n",
    "accuracy = correct_selections / K\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy on different subset:\", accuracy)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! You have completed the lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "[Joseph Santarcangelo](https://author.skills.network/instructors/joseph_santarcangelo) has a Ph.D. in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n",
    "\n",
    "[Ashutosh Sagar](https://www.linkedin.com/in/ashutoshsagar/) is completing his MS in CS from Dalhousie University. He has previous experience working with Natural Language Processing and as a Data Scientist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Contributors\n",
    "\n",
    "[Hailey Quach](https://author.skills.network/instructors/hailey_quach) is a Data Scientist at IBM. She's completing her Bsc, Honors in Computer Science at Concordia University, Montreal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© Copyright IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "e304da04016a4b41134ab217e0a1138cc3a8efdada740e1e4f9acc4b4e744ba9"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
